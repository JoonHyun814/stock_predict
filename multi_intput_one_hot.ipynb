{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, LSTM\n",
    "from tensorflow.keras.models import Model,load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LGE_onehot', 'NAVER_onehot', 'SamsungBL_onehot', 'SamsungEU_onehot', 'SamsungE_onehot', 'SKH_onehot']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekdate</th>\n",
       "      <th>SamsungE_RU</th>\n",
       "      <th>SamsungE_U</th>\n",
       "      <th>SamsungE_UC</th>\n",
       "      <th>SamsungE_D</th>\n",
       "      <th>SamsungE_RD</th>\n",
       "      <th>SamsungE_end</th>\n",
       "      <th>SamsungE_start</th>\n",
       "      <th>SamsungE_high</th>\n",
       "      <th>SamsungE_low</th>\n",
       "      <th>SamsungE_abount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17/01/02</th>\n",
       "      <td>0</td>\n",
       "      <td>1805000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1799000</td>\n",
       "      <td>1812000</td>\n",
       "      <td>1794000</td>\n",
       "      <td>93012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/03</th>\n",
       "      <td>1</td>\n",
       "      <td>1824000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1814000</td>\n",
       "      <td>1831000</td>\n",
       "      <td>1801000</td>\n",
       "      <td>147153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/04</th>\n",
       "      <td>2</td>\n",
       "      <td>1808000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1825000</td>\n",
       "      <td>1826000</td>\n",
       "      <td>1805000</td>\n",
       "      <td>159435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/05</th>\n",
       "      <td>3</td>\n",
       "      <td>1778000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1803000</td>\n",
       "      <td>1803000</td>\n",
       "      <td>1777000</td>\n",
       "      <td>219349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/06</th>\n",
       "      <td>4</td>\n",
       "      <td>1810000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1809000</td>\n",
       "      <td>1822000</td>\n",
       "      <td>1802000</td>\n",
       "      <td>177619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weekdate  SamsungE_RU  SamsungE_U  SamsungE_UC  SamsungE_D  \\\n",
       "date                                                                   \n",
       "17/01/02         0      1805000         0.0          0.0         1.0   \n",
       "17/01/03         1      1824000         0.0          1.0         0.0   \n",
       "17/01/04         2      1808000         0.0          0.0         0.5   \n",
       "17/01/05         3      1778000         0.0          0.0         0.0   \n",
       "17/01/06         4      1810000         0.0          1.0         0.0   \n",
       "\n",
       "          SamsungE_RD  SamsungE_end  SamsungE_start  SamsungE_high  \\\n",
       "date                                                                 \n",
       "17/01/02          0.0           0.0         1799000        1812000   \n",
       "17/01/03          0.0           0.0         1814000        1831000   \n",
       "17/01/04          0.5           0.0         1825000        1826000   \n",
       "17/01/05          1.0           0.0         1803000        1803000   \n",
       "17/01/06          0.0           0.0         1809000        1822000   \n",
       "\n",
       "          SamsungE_low  SamsungE_abount  \n",
       "date                                     \n",
       "17/01/02       1794000            93012  \n",
       "17/01/03       1801000           147153  \n",
       "17/01/04       1805000           159435  \n",
       "17/01/05       1777000           219349  \n",
       "17/01/06       1802000           177619  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_lst = list(map(lambda x: x[7:-4], glob.glob(r\"./data/*_onehot.csv\")))\n",
    "print(name_lst)\n",
    "data = pd.read_csv('./data/SamsungE_onehot.csv', index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekdate</th>\n",
       "      <th>LGE_RU</th>\n",
       "      <th>LGE_U</th>\n",
       "      <th>LGE_UC</th>\n",
       "      <th>LGE_D</th>\n",
       "      <th>LGE_RD</th>\n",
       "      <th>LGE_end</th>\n",
       "      <th>LGE_start</th>\n",
       "      <th>LGE_high</th>\n",
       "      <th>LGE_low</th>\n",
       "      <th>...</th>\n",
       "      <th>SKH_RU</th>\n",
       "      <th>SKH_U</th>\n",
       "      <th>SKH_UC</th>\n",
       "      <th>SKH_D</th>\n",
       "      <th>SKH_RD</th>\n",
       "      <th>SKH_end</th>\n",
       "      <th>SKH_start</th>\n",
       "      <th>SKH_high</th>\n",
       "      <th>SKH_low</th>\n",
       "      <th>SKH_abount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17/01/02</th>\n",
       "      <td>0</td>\n",
       "      <td>51600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51800</td>\n",
       "      <td>52300</td>\n",
       "      <td>51600</td>\n",
       "      <td>...</td>\n",
       "      <td>45800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44750</td>\n",
       "      <td>46000</td>\n",
       "      <td>44600</td>\n",
       "      <td>1547681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/03</th>\n",
       "      <td>1</td>\n",
       "      <td>54300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51800</td>\n",
       "      <td>54400</td>\n",
       "      <td>51800</td>\n",
       "      <td>...</td>\n",
       "      <td>47250</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46200</td>\n",
       "      <td>47300</td>\n",
       "      <td>46200</td>\n",
       "      <td>2655477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/04</th>\n",
       "      <td>2</td>\n",
       "      <td>53800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54200</td>\n",
       "      <td>54500</td>\n",
       "      <td>53100</td>\n",
       "      <td>...</td>\n",
       "      <td>46500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47000</td>\n",
       "      <td>47150</td>\n",
       "      <td>46200</td>\n",
       "      <td>2722599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/05</th>\n",
       "      <td>3</td>\n",
       "      <td>53600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54000</td>\n",
       "      <td>55700</td>\n",
       "      <td>53400</td>\n",
       "      <td>...</td>\n",
       "      <td>46950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47000</td>\n",
       "      <td>47500</td>\n",
       "      <td>46850</td>\n",
       "      <td>2377163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/06</th>\n",
       "      <td>4</td>\n",
       "      <td>52600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53800</td>\n",
       "      <td>54000</td>\n",
       "      <td>52400</td>\n",
       "      <td>...</td>\n",
       "      <td>48000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47700</td>\n",
       "      <td>48450</td>\n",
       "      <td>47600</td>\n",
       "      <td>3166843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          weekdate  LGE_RU  LGE_U  LGE_UC  LGE_D  LGE_RD  LGE_end  LGE_start  \\\n",
       "date                                                                           \n",
       "17/01/02         0   51600    0.0     0.0    1.0     0.0      0.0      51800   \n",
       "17/01/03         1   54300    1.0     0.0    0.0     0.0      0.0      51800   \n",
       "17/01/04         2   53800    0.0     0.0    0.5     0.5      0.0      54200   \n",
       "17/01/05         3   53600    0.0     0.0    1.0     0.0      0.0      54000   \n",
       "17/01/06         4   52600    0.0     0.0    0.0     1.0      0.0      53800   \n",
       "\n",
       "          LGE_high  LGE_low  ...  SKH_RU  SKH_U  SKH_UC  SKH_D  SKH_RD  \\\n",
       "date                         ...                                         \n",
       "17/01/02     52300    51600  ...   45800    0.0     1.0    0.0     0.0   \n",
       "17/01/03     54400    51800  ...   47250    0.5     0.5    0.0     0.0   \n",
       "17/01/04     54500    53100  ...   46500    0.0     0.0    0.0     1.0   \n",
       "17/01/05     55700    53400  ...   46950    0.0     0.5    0.5     0.0   \n",
       "17/01/06     54000    52400  ...   48000    0.0     1.0    0.0     0.0   \n",
       "\n",
       "          SKH_end  SKH_start  SKH_high  SKH_low  SKH_abount  \n",
       "date                                                         \n",
       "17/01/02      0.0      44750     46000    44600     1547681  \n",
       "17/01/03      0.0      46200     47300    46200     2655477  \n",
       "17/01/04      0.0      47000     47150    46200     2722599  \n",
       "17/01/05      0.0      47000     47500    46850     2377163  \n",
       "17/01/06      0.0      47700     48450    47600     3166843  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = [pd.read_csv(path, index_col = 0) for path in glob.glob(r\"./data/*_onehot.csv\")]\n",
    "data = datas[0]\n",
    "\n",
    "for d in datas[1:]:\n",
    "    data = pd.merge(data,d,left_index=True, right_index=True, on = 'weekdate')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257282</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.262136</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.291143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233010</td>\n",
       "      <td>0.247573</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.298502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233010</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>0.218447</td>\n",
       "      <td>0.260629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.373786</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.347208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1    2    3    4    5    6         7         8         9   ...  \\\n",
       "0  0.00  0.037037  0.0  0.0  1.0  0.0  0.0  0.055556  0.101852  0.037037  ...   \n",
       "1  0.25  0.287037  1.0  0.0  0.0  0.0  0.0  0.055556  0.296296  0.055556  ...   \n",
       "2  0.50  0.240741  0.0  0.0  0.5  0.5  0.0  0.277778  0.305556  0.175926  ...   \n",
       "3  0.75  0.222222  0.0  0.0  1.0  0.0  0.0  0.259259  0.416667  0.203704  ...   \n",
       "4  1.00  0.129630  0.0  0.0  0.0  1.0  0.0  0.240741  0.259259  0.111111  ...   \n",
       "\n",
       "         51   52   53   54   55   56        57        58        59        60  \n",
       "0  0.116505  0.0  1.0  0.0  0.0  0.0  0.014563  0.135922  0.000000  0.169686  \n",
       "1  0.257282  0.5  0.5  0.0  0.0  0.0  0.155340  0.262136  0.155340  0.291143  \n",
       "2  0.184466  0.0  0.0  0.0  1.0  0.0  0.233010  0.247573  0.155340  0.298502  \n",
       "3  0.228155  0.0  0.5  0.5  0.0  0.0  0.233010  0.281553  0.218447  0.260629  \n",
       "4  0.330097  0.0  1.0  0.0  0.0  0.0  0.300971  0.373786  0.291262  0.347208  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moving_window(data,sequence_num,step):\n",
    "    X_train = []\n",
    "    for i in range(0,len(data)-sequence_num,step):\n",
    "        X_train.append(data[i:i+sequence_num])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    return X_train\n",
    "\n",
    "train = moving_window(data,30,1)\n",
    "\n",
    "def normalization(train):\n",
    "    global name_lst\n",
    "    for t in train:\n",
    "        t[:,0] = t[:,0]/4\n",
    "        a_num = 10\n",
    "        for i in range(len(name_lst)):\n",
    "            p_max = t[:,8+ i*a_num].max(axis = 0)\n",
    "            p_min = t[:,9+ i*a_num].min(axis = 0)\n",
    "            a_max = t[:,10+ i*a_num].max(axis = 0)\n",
    "            t[:,1+i*a_num] = (t[:,1+i*a_num] - p_min)/(p_max-p_min)\n",
    "            t[:,7+i*a_num] = (t[:,7+i*a_num] - p_min)/(p_max-p_min)\n",
    "            t[:,8+i*a_num] = (t[:,8+i*a_num] - p_min)/(p_max-p_min)\n",
    "            t[:,9+i*a_num] = (t[:,9+i*a_num] - p_min)/(p_max-p_min)\n",
    "            t[:,10+i*a_num] = t[:,10+i*a_num]/a_max\n",
    "            \n",
    "normalization(train)\n",
    "df = pd.DataFrame(train[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_list = list(np.where(np.isnan(train)==True)[0])\n",
    "train = np.delete(train, nan_list,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 29, 61)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 29, 64)            32256     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 29, 32)            12416     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 29, 16)            3136      \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 29, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 5)                 280       \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 1, 5)              0         \n",
      "=================================================================\n",
      "Total params: 48,888\n",
      "Trainable params: 48,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LReLU = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "X = Input(shape=[29,61])\n",
    "H = LSTM(64,activation = LReLU, return_sequences = True)(X)\n",
    "H = LSTM(32,activation = LReLU, return_sequences = True)(H)\n",
    "H = LSTM(16,activation = LReLU, return_sequences = True)(H)\n",
    "H = LSTM(8,activation = LReLU, return_sequences = True)(H)\n",
    "H = LSTM(5,activation = 'softmax', return_sequences = False)(H)\n",
    "Y = tf.keras.layers.Reshape((1,5))(H)\n",
    "model = Model(X, Y)\n",
    "\n",
    "cross = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False, label_smoothing=0, reduction=\"auto\", name=\"categorical_crossentropy\")\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam,loss=cross)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "57/57 [==============================] - 7s 34ms/step - loss: 1.3749 - val_loss: 1.4316\n",
      "Epoch 2/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3852 - val_loss: 1.4399\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3898 - val_loss: 1.4383\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3940 - val_loss: 1.4371\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3708 - val_loss: 1.4357\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3684 - val_loss: 1.4329\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3901 - val_loss: 1.4300\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3598 - val_loss: 1.4310\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3689 - val_loss: 1.4335\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3777 - val_loss: 1.4516\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3791 - val_loss: 1.4365\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3525 - val_loss: 1.4367\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3836 - val_loss: 1.4440\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3624 - val_loss: 1.4357\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3801 - val_loss: 1.4365\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3328 - val_loss: 1.4352\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3488 - val_loss: 1.4393\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3638 - val_loss: 1.4325\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3551 - val_loss: 1.4473\n",
      "Epoch 20/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3654 - val_loss: 1.4461\n",
      "Epoch 21/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3651 - val_loss: 1.4586\n",
      "Epoch 22/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3418 - val_loss: 1.4351\n",
      "Epoch 23/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3397 - val_loss: 1.4397\n",
      "Epoch 24/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3726 - val_loss: 1.4374\n",
      "Epoch 25/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3696 - val_loss: 1.4493\n",
      "Epoch 26/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3255 - val_loss: 1.4541\n",
      "Epoch 27/500\n",
      "57/57 [==============================] - 1s 24ms/step - loss: 1.3403 - val_loss: 1.4435\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam,loss=cross)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 20, restore_best_weights = True)\n",
    "history = model.fit(train[:,0:29],train[:,29:30,[2,3,4,5,6]],epochs = 500,callbacks=[early_stopping],batch_size = 20,validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "57/57 [==============================] - 7s 37ms/step - loss: 1.3765 - val_loss: 1.4292\n",
      "Epoch 2/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3507 - val_loss: 1.4304\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3491 - val_loss: 1.4295\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3761 - val_loss: 1.4299\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3798 - val_loss: 1.4309\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3593 - val_loss: 1.4319\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3659 - val_loss: 1.4311\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3613 - val_loss: 1.4315\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3557 - val_loss: 1.4318\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3839 - val_loss: 1.4316\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3708 - val_loss: 1.4325\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3526 - val_loss: 1.4323\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3612 - val_loss: 1.4330\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3579 - val_loss: 1.4331\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3733 - val_loss: 1.4324\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3516 - val_loss: 1.4330\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3426 - val_loss: 1.4325\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3783 - val_loss: 1.4329\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3782 - val_loss: 1.4334\n",
      "Epoch 20/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3745 - val_loss: 1.4334\n",
      "Epoch 21/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3605 - val_loss: 1.4336\n",
      "Epoch 22/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3873 - val_loss: 1.4332\n",
      "Epoch 23/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3668 - val_loss: 1.4331\n",
      "Epoch 24/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3554 - val_loss: 1.4336\n",
      "Epoch 25/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3504 - val_loss: 1.4334\n",
      "Epoch 26/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3714 - val_loss: 1.4333\n",
      "Epoch 27/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3594 - val_loss: 1.4337\n",
      "Epoch 28/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3765 - val_loss: 1.4334\n",
      "Epoch 29/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3785 - val_loss: 1.4337\n",
      "Epoch 30/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3707 - val_loss: 1.4338\n",
      "Epoch 31/500\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.3590 - val_loss: 1.4351\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam,loss=cross)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 30, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(train[:,0:29],train[:,29:30,[2,3,4,5,6]],epochs = 500,callbacks=[early_stopping], batch_size = 20,validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = model.predict(train[:,0:29])\n",
    "np.where(Y>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.  1.  0.  0.  0. ]]\n",
      "\n",
      " [[0.  0.5 0.5 0.  0. ]]\n",
      "\n",
      " [[0.  0.5 0.5 0.  0. ]]\n",
      "\n",
      " [[0.  0.  0.  1.  0. ]]\n",
      "\n",
      " [[0.  0.5 0.5 0.  0. ]]\n",
      "\n",
      " [[0.  0.  1.  0.  0. ]]\n",
      "\n",
      " [[0.  1.  0.  0.  0. ]]\n",
      "\n",
      " [[0.  0.  1.  0.  0. ]]\n",
      "\n",
      " [[0.  0.  0.5 0.5 0. ]]\n",
      "\n",
      " [[0.  0.  0.  0.  1. ]]\n",
      "\n",
      " [[0.  1.  0.  0.  0. ]]\n",
      "\n",
      " [[0.5 0.5 0.  0.  0. ]]\n",
      "\n",
      " [[0.  0.5 0.5 0.  0. ]]\n",
      "\n",
      " [[0.  0.  0.  0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5 0.  0.  0. ]]]\n"
     ]
    }
   ],
   "source": [
    "print(train[:15,29:30,2:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev = train[:,29:30,2]*Y\n",
    "plt.plot(ev)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1029"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(ev > 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
