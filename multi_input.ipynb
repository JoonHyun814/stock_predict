{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, LSTM\n",
    "from tensorflow.keras.models import Model,load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LGE', 'NAVER', 'SamsungBL', 'SamsungE', 'SamsungEU', 'SKH']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekdate</th>\n",
       "      <th>SamsungE_end</th>\n",
       "      <th>SamsungE_dpp</th>\n",
       "      <th>SamsungE_start</th>\n",
       "      <th>SamsungE_high</th>\n",
       "      <th>SamsungE_low</th>\n",
       "      <th>SamsungE_abount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17/01/02</th>\n",
       "      <td>0</td>\n",
       "      <td>1805000</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1799000</td>\n",
       "      <td>1812000</td>\n",
       "      <td>1794000</td>\n",
       "      <td>93012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/03</th>\n",
       "      <td>1</td>\n",
       "      <td>1824000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1814000</td>\n",
       "      <td>1831000</td>\n",
       "      <td>1801000</td>\n",
       "      <td>147153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/04</th>\n",
       "      <td>2</td>\n",
       "      <td>1808000</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>1825000</td>\n",
       "      <td>1826000</td>\n",
       "      <td>1805000</td>\n",
       "      <td>159435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/05</th>\n",
       "      <td>3</td>\n",
       "      <td>1778000</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>1803000</td>\n",
       "      <td>1803000</td>\n",
       "      <td>1777000</td>\n",
       "      <td>219349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/06</th>\n",
       "      <td>4</td>\n",
       "      <td>1810000</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1809000</td>\n",
       "      <td>1822000</td>\n",
       "      <td>1802000</td>\n",
       "      <td>177619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weekdate  SamsungE_end  SamsungE_dpp  SamsungE_start  SamsungE_high  \\\n",
       "date                                                                            \n",
       "17/01/02         0       1805000          0.17         1799000        1812000   \n",
       "17/01/03         1       1824000          1.05         1814000        1831000   \n",
       "17/01/04         2       1808000         -0.88         1825000        1826000   \n",
       "17/01/05         3       1778000         -1.66         1803000        1803000   \n",
       "17/01/06         4       1810000          1.80         1809000        1822000   \n",
       "\n",
       "          SamsungE_low  SamsungE_abount  \n",
       "date                                     \n",
       "17/01/02       1794000            93012  \n",
       "17/01/03       1801000           147153  \n",
       "17/01/04       1805000           159435  \n",
       "17/01/05       1777000           219349  \n",
       "17/01/06       1802000           177619  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_lst = list(map(lambda x: x[7:-4], glob.glob(r\"./data/*.csv\")))\n",
    "print(name_lst)\n",
    "data = pd.read_csv('./data/SamsungE.csv', index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekdate</th>\n",
       "      <th>LGE_end</th>\n",
       "      <th>LGE_dpp</th>\n",
       "      <th>LGE_start</th>\n",
       "      <th>LGE_high</th>\n",
       "      <th>LGE_low</th>\n",
       "      <th>LGE_abount</th>\n",
       "      <th>NAVER_end</th>\n",
       "      <th>NAVER_dpp</th>\n",
       "      <th>NAVER_start</th>\n",
       "      <th>...</th>\n",
       "      <th>SamsungEU_start</th>\n",
       "      <th>SamsungEU_high</th>\n",
       "      <th>SamsungEU_low</th>\n",
       "      <th>SamsungEU_abount</th>\n",
       "      <th>SKH_end</th>\n",
       "      <th>SKH_dpp</th>\n",
       "      <th>SKH_start</th>\n",
       "      <th>SKH_high</th>\n",
       "      <th>SKH_low</th>\n",
       "      <th>SKH_abount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17/01/02</th>\n",
       "      <td>0</td>\n",
       "      <td>51600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51800</td>\n",
       "      <td>52300</td>\n",
       "      <td>51600</td>\n",
       "      <td>431474</td>\n",
       "      <td>777000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>778000</td>\n",
       "      <td>...</td>\n",
       "      <td>1432000</td>\n",
       "      <td>1448000</td>\n",
       "      <td>1415000</td>\n",
       "      <td>10822</td>\n",
       "      <td>45800</td>\n",
       "      <td>2.46</td>\n",
       "      <td>44750</td>\n",
       "      <td>46000</td>\n",
       "      <td>44600</td>\n",
       "      <td>1547681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/03</th>\n",
       "      <td>1</td>\n",
       "      <td>54300</td>\n",
       "      <td>5.23</td>\n",
       "      <td>51800</td>\n",
       "      <td>54400</td>\n",
       "      <td>51800</td>\n",
       "      <td>1715000</td>\n",
       "      <td>767000</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>777000</td>\n",
       "      <td>...</td>\n",
       "      <td>1440000</td>\n",
       "      <td>1448000</td>\n",
       "      <td>1422000</td>\n",
       "      <td>23904</td>\n",
       "      <td>47250</td>\n",
       "      <td>3.17</td>\n",
       "      <td>46200</td>\n",
       "      <td>47300</td>\n",
       "      <td>46200</td>\n",
       "      <td>2655477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/04</th>\n",
       "      <td>2</td>\n",
       "      <td>53800</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>54200</td>\n",
       "      <td>54500</td>\n",
       "      <td>53100</td>\n",
       "      <td>1262418</td>\n",
       "      <td>810000</td>\n",
       "      <td>5.61</td>\n",
       "      <td>775000</td>\n",
       "      <td>...</td>\n",
       "      <td>1451000</td>\n",
       "      <td>1452000</td>\n",
       "      <td>1425000</td>\n",
       "      <td>37092</td>\n",
       "      <td>46500</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>47000</td>\n",
       "      <td>47150</td>\n",
       "      <td>46200</td>\n",
       "      <td>2722599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/05</th>\n",
       "      <td>3</td>\n",
       "      <td>53600</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>54000</td>\n",
       "      <td>55700</td>\n",
       "      <td>53400</td>\n",
       "      <td>1428250</td>\n",
       "      <td>791000</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>810000</td>\n",
       "      <td>...</td>\n",
       "      <td>1430000</td>\n",
       "      <td>1433000</td>\n",
       "      <td>1411000</td>\n",
       "      <td>47714</td>\n",
       "      <td>46950</td>\n",
       "      <td>0.97</td>\n",
       "      <td>47000</td>\n",
       "      <td>47500</td>\n",
       "      <td>46850</td>\n",
       "      <td>2377163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/01/06</th>\n",
       "      <td>4</td>\n",
       "      <td>52600</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>53800</td>\n",
       "      <td>54000</td>\n",
       "      <td>52400</td>\n",
       "      <td>1382362</td>\n",
       "      <td>799000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>791000</td>\n",
       "      <td>...</td>\n",
       "      <td>1430000</td>\n",
       "      <td>1438000</td>\n",
       "      <td>1423000</td>\n",
       "      <td>24743</td>\n",
       "      <td>48000</td>\n",
       "      <td>2.24</td>\n",
       "      <td>47700</td>\n",
       "      <td>48450</td>\n",
       "      <td>47600</td>\n",
       "      <td>3166843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          weekdate  LGE_end  LGE_dpp  LGE_start  LGE_high  LGE_low  \\\n",
       "date                                                                 \n",
       "17/01/02         0    51600     0.00      51800     52300    51600   \n",
       "17/01/03         1    54300     5.23      51800     54400    51800   \n",
       "17/01/04         2    53800    -0.92      54200     54500    53100   \n",
       "17/01/05         3    53600    -0.37      54000     55700    53400   \n",
       "17/01/06         4    52600    -1.87      53800     54000    52400   \n",
       "\n",
       "          LGE_abount  NAVER_end  NAVER_dpp  NAVER_start  ...  SamsungEU_start  \\\n",
       "date                                                     ...                    \n",
       "17/01/02      431474     777000       0.26       778000  ...          1432000   \n",
       "17/01/03     1715000     767000      -1.29       777000  ...          1440000   \n",
       "17/01/04     1262418     810000       5.61       775000  ...          1451000   \n",
       "17/01/05     1428250     791000      -2.35       810000  ...          1430000   \n",
       "17/01/06     1382362     799000       1.01       791000  ...          1430000   \n",
       "\n",
       "          SamsungEU_high  SamsungEU_low  SamsungEU_abount  SKH_end  SKH_dpp  \\\n",
       "date                                                                          \n",
       "17/01/02         1448000        1415000             10822    45800     2.46   \n",
       "17/01/03         1448000        1422000             23904    47250     3.17   \n",
       "17/01/04         1452000        1425000             37092    46500    -1.59   \n",
       "17/01/05         1433000        1411000             47714    46950     0.97   \n",
       "17/01/06         1438000        1423000             24743    48000     2.24   \n",
       "\n",
       "          SKH_start  SKH_high  SKH_low  SKH_abount  \n",
       "date                                                \n",
       "17/01/02      44750     46000    44600     1547681  \n",
       "17/01/03      46200     47300    46200     2655477  \n",
       "17/01/04      47000     47150    46200     2722599  \n",
       "17/01/05      47000     47500    46850     2377163  \n",
       "17/01/06      47700     48450    47600     3166843  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = [pd.read_csv(path, index_col = 0) for path in glob.glob(r\"./data/*.csv\")]\n",
    "data = datas[0]\n",
    "\n",
    "for d in datas[1:]:\n",
    "    data = pd.merge(data,d,left_index=True, right_index=True, on = 'weekdate')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.188724</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.178744</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.750129</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140097</td>\n",
       "      <td>0.178744</td>\n",
       "      <td>0.053140</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.257282</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.262136</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.291143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>0.552173</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193237</td>\n",
       "      <td>0.198068</td>\n",
       "      <td>0.067633</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>0.233010</td>\n",
       "      <td>0.247573</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.298502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.624707</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.106280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030057</td>\n",
       "      <td>0.228155</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.233010</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>0.218447</td>\n",
       "      <td>0.260629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.604636</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.015587</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.373786</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.347208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1      2         3         4         5         6         7   \\\n",
       "0  0.00  0.037037  0.000  0.055556  0.101852  0.037037  0.188724  0.518987   \n",
       "1  0.25  0.287037  0.523  0.055556  0.296296  0.055556  0.750129  0.392405   \n",
       "2  0.50  0.240741 -0.092  0.277778  0.305556  0.175926  0.552173  0.936709   \n",
       "3  0.75  0.222222 -0.037  0.259259  0.416667  0.203704  0.624707  0.696203   \n",
       "4  1.00  0.129630 -0.187  0.240741  0.259259  0.111111  0.604636  0.797468   \n",
       "\n",
       "      8         9   ...        27        28        29        30        31  \\\n",
       "0  0.026  0.531646  ...  0.101449  0.178744  0.019324  0.006817  0.116505   \n",
       "1 -0.129  0.518987  ...  0.140097  0.178744  0.053140  0.015058  0.257282   \n",
       "2  0.561  0.493671  ...  0.193237  0.198068  0.067633  0.023366  0.184466   \n",
       "3 -0.235  0.936709  ...  0.091787  0.106280  0.000000  0.030057  0.228155   \n",
       "4  0.101  0.696203  ...  0.091787  0.130435  0.057971  0.015587  0.330097   \n",
       "\n",
       "      32        33        34        35        36  \n",
       "0  0.246  0.014563  0.135922  0.000000  0.169686  \n",
       "1  0.317  0.155340  0.262136  0.155340  0.291143  \n",
       "2 -0.159  0.233010  0.247573  0.155340  0.298502  \n",
       "3  0.097  0.233010  0.281553  0.218447  0.260629  \n",
       "4  0.224  0.300971  0.373786  0.291262  0.347208  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moving_window(data,sequence_num,step):\n",
    "    X_train = []\n",
    "    for i in range(0,len(data)-sequence_num,step):\n",
    "        X_train.append(data[i:i+sequence_num])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    return X_train\n",
    "\n",
    "train = moving_window(data,30,1)\n",
    "\n",
    "def normalization(train):\n",
    "    global name_lst\n",
    "    for t in train:\n",
    "        t[:,0] = t[:,0]/4\n",
    "        for i in range(len(name_lst)):\n",
    "            p_max = t.max(axis = 0)[4+ i*6]\n",
    "            p_min = t.min(axis = 0)[5+ i*6]\n",
    "            a_max = t.max(axis = 0)[6+ i*6]\n",
    "            t[:,1+i*6] = (t[:,1+i*6] - p_min)/(p_max-p_min)\n",
    "            t[:,3+i*6] = (t[:,3+i*6] - p_min)/(p_max-p_min)\n",
    "            t[:,4+i*6] = (t[:,4+i*6] - p_min)/(p_max-p_min)\n",
    "            t[:,5+i*6] = (t[:,5+i*6] - p_min)/(p_max-p_min)\n",
    "            t[:,2+i*6] = t[:,2+i*6]/10\n",
    "            t[:,6+i*6] = t[:,6+i*6]/a_max\n",
    "            \n",
    "normalization(train)\n",
    "df = pd.DataFrame(train[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_list = list(np.where(np.isnan(train)==True)[0])\n",
    "train = np.delete(train, nan_list,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 29, 37)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 29, 64)            26112     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 29, 32)            12416     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 29, 16)            3136      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 29, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 29, 4)             208       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 42,696\n",
      "Trainable params: 42,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = Input(shape=[29,37])\n",
    "H = LSTM(64,activation = 'tanh', return_sequences = True)(X)\n",
    "H = LSTM(32,activation = 'tanh', return_sequences = True)(H)\n",
    "H = LSTM(16,activation = 'tanh', return_sequences = True)(H)\n",
    "H = LSTM(8,activation = 'tanh', return_sequences = True)(H)\n",
    "H = LSTM(4,activation = 'tanh', return_sequences = True)(H)\n",
    "Y = LSTM(1,activation = 'tanh', return_sequences = False)(H)\n",
    "LGE_model = Model(X, Y)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "LGE_model.compile(optimizer=adam,loss='mae')\n",
    "LGE_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57/57 [==============================] - 13s 83ms/step - loss: 0.1811 - val_loss: 0.1898\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1773 - val_loss: 0.1894\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1751 - val_loss: 0.1886\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1688 - val_loss: 0.1886\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1743 - val_loss: 0.1891\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1673 - val_loss: 0.1887\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1708 - val_loss: 0.1892\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1735 - val_loss: 0.1885\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1716 - val_loss: 0.1885\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1854 - val_loss: 0.1885\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1806 - val_loss: 0.1887\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1731 - val_loss: 0.1886\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1694 - val_loss: 0.1886\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1725 - val_loss: 0.1887\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1861 - val_loss: 0.1887\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1779 - val_loss: 0.1885\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1698 - val_loss: 0.1886\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1759 - val_loss: 0.1888\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1707 - val_loss: 0.1887\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1757 - val_loss: 0.1887\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1791 - val_loss: 0.1884\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1764 - val_loss: 0.1884\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1742 - val_loss: 0.1892\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1770 - val_loss: 0.1885\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1685 - val_loss: 0.1884\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1707 - val_loss: 0.1887\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1749 - val_loss: 0.1884\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1794 - val_loss: 0.1884\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1772 - val_loss: 0.1887\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1794 - val_loss: 0.1884\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1724 - val_loss: 0.1890\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1762 - val_loss: 0.1885\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1768 - val_loss: 0.1896\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1690 - val_loss: 0.1882\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1770 - val_loss: 0.1881\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1681 - val_loss: 0.1884\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1698 - val_loss: 0.1884\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1741 - val_loss: 0.1907\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1765 - val_loss: 0.1881\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1697 - val_loss: 0.1891\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1673 - val_loss: 0.1894\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1677 - val_loss: 0.1886\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1778 - val_loss: 0.1884\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.1694 - val_loss: 0.1905\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1773 - val_loss: 0.1887\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1752 - val_loss: 0.1890\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1747 - val_loss: 0.1879\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1656 - val_loss: 0.1886\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1763 - val_loss: 0.1883\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1718 - val_loss: 0.1898\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1700 - val_loss: 0.1880\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1688 - val_loss: 0.1893\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1763 - val_loss: 0.1894\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1734 - val_loss: 0.1898\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1636 - val_loss: 0.1886\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1737 - val_loss: 0.1882\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1618 - val_loss: 0.1876\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1737 - val_loss: 0.1892\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1647 - val_loss: 0.1876\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1654 - val_loss: 0.1868\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1667 - val_loss: 0.1887\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1771 - val_loss: 0.1880\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1647 - val_loss: 0.1876\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1758 - val_loss: 0.1875\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1737 - val_loss: 0.1886\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1655 - val_loss: 0.1896\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1658 - val_loss: 0.1887\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1798 - val_loss: 0.1891\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1621 - val_loss: 0.1871\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.1600 - val_loss: 0.1888\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.1594 - val_loss: 0.1886\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1649 - val_loss: 0.1875\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1709 - val_loss: 0.1901\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1710 - val_loss: 0.1905\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1695 - val_loss: 0.1889\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1623 - val_loss: 0.1893\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1652 - val_loss: 0.1894\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1789 - val_loss: 0.1880\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1786 - val_loss: 0.1902\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.1757 - val_loss: 0.1885\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1635 - val_loss: 0.1886\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1682 - val_loss: 0.1883\n",
      "Epoch 83/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1617 - val_loss: 0.1887\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1645 - val_loss: 0.1890\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1735 - val_loss: 0.1919\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 0.1752 - val_loss: 0.1878\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1662 - val_loss: 0.1907\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1663 - val_loss: 0.1899\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1606 - val_loss: 0.1897\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 0.1689 - val_loss: 0.1893\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.1592 - val_loss: 0.1898\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 0.1588 - val_loss: 0.1885\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.1756 - val_loss: 0.1894\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.1588 - val_loss: 0.1903\n",
      "Epoch 95/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1639 - val_loss: 0.1893\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1673 - val_loss: 0.1919\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1571 - val_loss: 0.1907\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1659 - val_loss: 0.1924\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1626 - val_loss: 0.1920\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1672 - val_loss: 0.1907\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "LGE_model.compile(optimizer=adam,loss='mae')\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 20, restore_best_weights = True)\n",
    "# callbacks=[early_stopping]\n",
    "history = LGE_model.fit(train[:,0:29],train[:,29:30,2],epochs = 100,batch_size = 20, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "57/57 [==============================] - 15s 88ms/step - loss: 0.1764 - val_loss: 0.1934\n",
      "Epoch 2/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1628 - val_loss: 0.1949\n",
      "Epoch 3/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1599 - val_loss: 0.1947\n",
      "Epoch 4/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1694 - val_loss: 0.1930\n",
      "Epoch 5/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1658 - val_loss: 0.1942\n",
      "Epoch 6/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1642 - val_loss: 0.1938\n",
      "Epoch 7/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1723 - val_loss: 0.1947\n",
      "Epoch 8/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1637 - val_loss: 0.1941\n",
      "Epoch 9/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1627 - val_loss: 0.1922\n",
      "Epoch 10/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1693 - val_loss: 0.1937\n",
      "Epoch 11/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1671 - val_loss: 0.1928\n",
      "Epoch 12/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.1686 - val_loss: 0.1952\n",
      "Epoch 13/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.1699 - val_loss: 0.1935\n",
      "Epoch 14/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1643 - val_loss: 0.1950\n",
      "Epoch 15/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1687 - val_loss: 0.1941\n",
      "Epoch 16/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1673 - val_loss: 0.1935\n",
      "Epoch 17/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1659 - val_loss: 0.1951\n",
      "Epoch 18/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1609 - val_loss: 0.1962\n",
      "Epoch 19/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1626 - val_loss: 0.1975\n",
      "Epoch 20/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1693 - val_loss: 0.1986\n",
      "Epoch 21/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1581 - val_loss: 0.1936\n",
      "Epoch 22/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1591 - val_loss: 0.1966\n",
      "Epoch 23/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1676 - val_loss: 0.1953\n",
      "Epoch 24/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1666 - val_loss: 0.1989\n",
      "Epoch 25/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1593 - val_loss: 0.1918\n",
      "Epoch 26/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1586 - val_loss: 0.2005\n",
      "Epoch 27/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1556 - val_loss: 0.1949\n",
      "Epoch 28/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1552 - val_loss: 0.1996\n",
      "Epoch 29/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1618 - val_loss: 0.1978\n",
      "Epoch 30/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1577 - val_loss: 0.1966\n",
      "Epoch 31/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1616 - val_loss: 0.1931\n",
      "Epoch 32/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1643 - val_loss: 0.1987\n",
      "Epoch 33/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1575 - val_loss: 0.1957\n",
      "Epoch 34/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1589 - val_loss: 0.1949\n",
      "Epoch 35/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 36/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1543 - val_loss: 0.1941\n",
      "Epoch 37/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1510 - val_loss: 0.1970\n",
      "Epoch 38/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1571 - val_loss: 0.1962\n",
      "Epoch 39/1000\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.1646 - val_loss: 0.1952\n",
      "Epoch 40/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1620 - val_loss: 0.1952\n",
      "Epoch 41/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1522 - val_loss: 0.1986\n",
      "Epoch 42/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1623 - val_loss: 0.1984\n",
      "Epoch 43/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1625 - val_loss: 0.1948\n",
      "Epoch 44/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1567 - val_loss: 0.1956\n",
      "Epoch 45/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1633 - val_loss: 0.1962\n",
      "Epoch 46/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1615 - val_loss: 0.1972\n",
      "Epoch 47/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1679 - val_loss: 0.2008\n",
      "Epoch 48/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1566 - val_loss: 0.2000\n",
      "Epoch 49/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1549 - val_loss: 0.1984\n",
      "Epoch 50/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1610 - val_loss: 0.1988\n",
      "Epoch 51/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1586 - val_loss: 0.1959\n",
      "Epoch 52/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1599 - val_loss: 0.2006\n",
      "Epoch 53/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1515 - val_loss: 0.1959\n",
      "Epoch 54/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1638 - val_loss: 0.1991\n",
      "Epoch 55/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 56/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1596 - val_loss: 0.1947\n",
      "Epoch 57/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1577 - val_loss: 0.1966\n",
      "Epoch 58/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1631 - val_loss: 0.2011\n",
      "Epoch 59/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1579 - val_loss: 0.1995\n",
      "Epoch 60/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1525 - val_loss: 0.1990\n",
      "Epoch 61/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1549 - val_loss: 0.1940\n",
      "Epoch 62/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1590 - val_loss: 0.1972\n",
      "Epoch 63/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1522 - val_loss: 0.1988\n",
      "Epoch 64/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1499 - val_loss: 0.1965\n",
      "Epoch 65/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1519 - val_loss: 0.1968\n",
      "Epoch 66/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1556 - val_loss: 0.1999\n",
      "Epoch 67/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1584 - val_loss: 0.1988\n",
      "Epoch 68/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1494 - val_loss: 0.1960\n",
      "Epoch 69/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1570 - val_loss: 0.1980\n",
      "Epoch 70/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1493 - val_loss: 0.1971\n",
      "Epoch 71/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1484 - val_loss: 0.2003\n",
      "Epoch 72/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1581 - val_loss: 0.2009\n",
      "Epoch 73/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1554 - val_loss: 0.1965\n",
      "Epoch 74/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1507 - val_loss: 0.2014\n",
      "Epoch 75/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1441 - val_loss: 0.2012\n",
      "Epoch 76/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1525 - val_loss: 0.1988\n",
      "Epoch 77/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1526 - val_loss: 0.2028\n",
      "Epoch 78/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1560 - val_loss: 0.1984\n",
      "Epoch 79/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1630 - val_loss: 0.2012\n",
      "Epoch 80/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1545 - val_loss: 0.1982\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1566 - val_loss: 0.1987\n",
      "Epoch 82/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1477 - val_loss: 0.2065\n",
      "Epoch 83/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1600 - val_loss: 0.1993\n",
      "Epoch 84/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1531 - val_loss: 0.1991\n",
      "Epoch 85/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1471 - val_loss: 0.2037\n",
      "Epoch 86/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1509 - val_loss: 0.2025\n",
      "Epoch 87/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1557 - val_loss: 0.1997\n",
      "Epoch 88/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1573 - val_loss: 0.2015\n",
      "Epoch 89/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1535 - val_loss: 0.1986\n",
      "Epoch 90/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1512 - val_loss: 0.1999\n",
      "Epoch 91/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1485 - val_loss: 0.1996\n",
      "Epoch 92/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1482 - val_loss: 0.2074\n",
      "Epoch 93/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1581 - val_loss: 0.2026\n",
      "Epoch 94/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1476 - val_loss: 0.2026\n",
      "Epoch 95/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1480 - val_loss: 0.2088\n",
      "Epoch 96/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1436 - val_loss: 0.2046\n",
      "Epoch 97/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1496 - val_loss: 0.2056\n",
      "Epoch 98/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1490 - val_loss: 0.2046\n",
      "Epoch 99/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1462 - val_loss: 0.1991\n",
      "Epoch 100/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1569 - val_loss: 0.2050\n",
      "Epoch 101/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1544 - val_loss: 0.2023\n",
      "Epoch 102/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1484 - val_loss: 0.2044\n",
      "Epoch 103/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1439 - val_loss: 0.2020\n",
      "Epoch 104/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1512 - val_loss: 0.2019\n",
      "Epoch 105/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1576 - val_loss: 0.2053\n",
      "Epoch 106/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1490 - val_loss: 0.2039\n",
      "Epoch 107/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1472 - val_loss: 0.2049\n",
      "Epoch 108/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1591 - val_loss: 0.2050\n",
      "Epoch 109/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1409 - val_loss: 0.2059\n",
      "Epoch 110/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1459 - val_loss: 0.2039\n",
      "Epoch 111/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1489 - val_loss: 0.1997\n",
      "Epoch 112/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1440 - val_loss: 0.2066\n",
      "Epoch 113/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1476 - val_loss: 0.2043\n",
      "Epoch 114/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.1484 - val_loss: 0.1996\n",
      "Epoch 115/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1446 - val_loss: 0.2057\n",
      "Epoch 116/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1478 - val_loss: 0.2083\n",
      "Epoch 117/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1415 - val_loss: 0.2056\n",
      "Epoch 118/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1510 - val_loss: 0.2137\n",
      "Epoch 119/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1397 - val_loss: 0.2107\n",
      "Epoch 120/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1586 - val_loss: 0.2145\n",
      "Epoch 121/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.1545 - val_loss: 0.2091\n",
      "Epoch 122/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1448 - val_loss: 0.2106\n",
      "Epoch 123/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.1403 - val_loss: 0.2180\n",
      "Epoch 124/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.1441 - val_loss: 0.2150\n",
      "Epoch 125/1000\n",
      "57/57 [==============================] - 2s 39ms/step - loss: 0.1438 - val_loss: 0.2138\n",
      "Epoch 126/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1443 - val_loss: 0.2074\n",
      "Epoch 127/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1425 - val_loss: 0.2106\n",
      "Epoch 128/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1356 - val_loss: 0.2145\n",
      "Epoch 129/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1422 - val_loss: 0.2095\n",
      "Epoch 130/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1446 - val_loss: 0.2102\n",
      "Epoch 131/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1402 - val_loss: 0.2102\n",
      "Epoch 132/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1414 - val_loss: 0.2150\n",
      "Epoch 133/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1424 - val_loss: 0.2111\n",
      "Epoch 134/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1428 - val_loss: 0.2184\n",
      "Epoch 135/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1429 - val_loss: 0.2174\n",
      "Epoch 136/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.1413 - val_loss: 0.2184\n",
      "Epoch 137/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1521 - val_loss: 0.2175\n",
      "Epoch 138/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1439 - val_loss: 0.2218\n",
      "Epoch 139/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1437 - val_loss: 0.2213\n",
      "Epoch 140/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1385 - val_loss: 0.2156\n",
      "Epoch 141/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1450 - val_loss: 0.2145\n",
      "Epoch 142/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1339 - val_loss: 0.2202\n",
      "Epoch 143/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1399 - val_loss: 0.2143\n",
      "Epoch 144/1000\n",
      "57/57 [==============================] - 2s 39ms/step - loss: 0.1423 - val_loss: 0.2094\n",
      "Epoch 145/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1337 - val_loss: 0.2122\n",
      "Epoch 146/1000\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 0.1364 - val_loss: 0.2130\n",
      "Epoch 147/1000\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 0.1388 - val_loss: 0.2146\n",
      "Epoch 148/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1437 - val_loss: 0.2093\n",
      "Epoch 149/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1404 - val_loss: 0.2230\n",
      "Epoch 150/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1362 - val_loss: 0.2235\n",
      "Epoch 151/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1365 - val_loss: 0.2224\n",
      "Epoch 152/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1300 - val_loss: 0.2170\n",
      "Epoch 153/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1426 - val_loss: 0.2193\n",
      "Epoch 154/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1352 - val_loss: 0.2220\n",
      "Epoch 155/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1401 - val_loss: 0.2136\n",
      "Epoch 156/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1381 - val_loss: 0.2287\n",
      "Epoch 157/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1449 - val_loss: 0.2235\n",
      "Epoch 158/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1369 - val_loss: 0.2286\n",
      "Epoch 159/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1457 - val_loss: 0.2246\n",
      "Epoch 160/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1360 - val_loss: 0.2278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1357 - val_loss: 0.2262\n",
      "Epoch 162/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1410 - val_loss: 0.2236\n",
      "Epoch 163/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1289 - val_loss: 0.2276\n",
      "Epoch 164/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1412 - val_loss: 0.2236\n",
      "Epoch 165/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1465 - val_loss: 0.2261\n",
      "Epoch 166/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1365 - val_loss: 0.2223\n",
      "Epoch 167/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1359 - val_loss: 0.2175\n",
      "Epoch 168/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1289 - val_loss: 0.2256\n",
      "Epoch 169/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1294 - val_loss: 0.2325\n",
      "Epoch 170/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1346 - val_loss: 0.2326\n",
      "Epoch 171/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1352 - val_loss: 0.2261\n",
      "Epoch 172/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1271 - val_loss: 0.2280\n",
      "Epoch 173/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1309 - val_loss: 0.2343\n",
      "Epoch 174/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1318 - val_loss: 0.2316\n",
      "Epoch 175/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1376 - val_loss: 0.2176\n",
      "Epoch 176/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1380 - val_loss: 0.2325\n",
      "Epoch 177/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1316 - val_loss: 0.2207\n",
      "Epoch 178/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1326 - val_loss: 0.2272\n",
      "Epoch 179/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1322 - val_loss: 0.2218\n",
      "Epoch 180/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1325 - val_loss: 0.2313\n",
      "Epoch 181/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1265 - val_loss: 0.2320\n",
      "Epoch 182/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1416 - val_loss: 0.2230\n",
      "Epoch 183/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1321 - val_loss: 0.2379\n",
      "Epoch 184/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1406 - val_loss: 0.2295\n",
      "Epoch 185/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1234 - val_loss: 0.2311\n",
      "Epoch 186/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1243 - val_loss: 0.2267\n",
      "Epoch 187/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1350 - val_loss: 0.2308\n",
      "Epoch 188/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1352 - val_loss: 0.2353\n",
      "Epoch 189/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1292 - val_loss: 0.2363\n",
      "Epoch 190/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1311 - val_loss: 0.2372\n",
      "Epoch 191/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1326 - val_loss: 0.2353\n",
      "Epoch 192/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1291 - val_loss: 0.2389\n",
      "Epoch 193/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1295 - val_loss: 0.2349\n",
      "Epoch 194/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1267 - val_loss: 0.2327\n",
      "Epoch 195/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1266 - val_loss: 0.2378\n",
      "Epoch 196/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1292 - val_loss: 0.2351\n",
      "Epoch 197/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1299 - val_loss: 0.2310\n",
      "Epoch 198/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1330 - val_loss: 0.2227\n",
      "Epoch 199/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1262 - val_loss: 0.2314\n",
      "Epoch 200/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1244 - val_loss: 0.2358\n",
      "Epoch 201/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1252 - val_loss: 0.2361\n",
      "Epoch 202/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1172 - val_loss: 0.2340\n",
      "Epoch 203/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1250 - val_loss: 0.2351\n",
      "Epoch 204/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1238 - val_loss: 0.2322\n",
      "Epoch 205/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1384 - val_loss: 0.2458\n",
      "Epoch 206/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1196 - val_loss: 0.2425\n",
      "Epoch 207/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1311 - val_loss: 0.2390\n",
      "Epoch 208/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1213 - val_loss: 0.2420\n",
      "Epoch 209/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1228 - val_loss: 0.2386\n",
      "Epoch 210/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1329 - val_loss: 0.2339\n",
      "Epoch 211/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1279 - val_loss: 0.2408\n",
      "Epoch 212/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1169 - val_loss: 0.2364\n",
      "Epoch 213/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1226 - val_loss: 0.2344\n",
      "Epoch 214/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1205 - val_loss: 0.2464\n",
      "Epoch 215/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1193 - val_loss: 0.2389\n",
      "Epoch 216/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1290 - val_loss: 0.2433\n",
      "Epoch 217/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1283 - val_loss: 0.2389\n",
      "Epoch 218/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1248 - val_loss: 0.2258\n",
      "Epoch 219/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1229 - val_loss: 0.2380\n",
      "Epoch 220/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1308 - val_loss: 0.2409\n",
      "Epoch 221/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1167 - val_loss: 0.2420\n",
      "Epoch 222/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1296 - val_loss: 0.2449\n",
      "Epoch 223/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1124 - val_loss: 0.2485\n",
      "Epoch 224/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1144 - val_loss: 0.2302\n",
      "Epoch 225/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1230 - val_loss: 0.2544\n",
      "Epoch 226/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1228 - val_loss: 0.2436\n",
      "Epoch 227/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1283 - val_loss: 0.2425\n",
      "Epoch 228/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1184 - val_loss: 0.2530\n",
      "Epoch 229/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1185 - val_loss: 0.2256\n",
      "Epoch 230/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1238 - val_loss: 0.2434\n",
      "Epoch 231/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1183 - val_loss: 0.2437\n",
      "Epoch 232/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1239 - val_loss: 0.2407\n",
      "Epoch 233/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1127 - val_loss: 0.2426\n",
      "Epoch 234/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1124 - val_loss: 0.2435\n",
      "Epoch 235/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1100 - val_loss: 0.2408\n",
      "Epoch 236/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1183 - val_loss: 0.2498\n",
      "Epoch 237/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1122 - val_loss: 0.2477\n",
      "Epoch 238/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1172 - val_loss: 0.2362\n",
      "Epoch 239/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1335 - val_loss: 0.2514\n",
      "Epoch 240/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1254 - val_loss: 0.2513\n",
      "Epoch 241/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1157 - val_loss: 0.2511\n",
      "Epoch 242/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1152 - val_loss: 0.2270\n",
      "Epoch 243/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1257 - val_loss: 0.2468\n",
      "Epoch 244/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1243 - val_loss: 0.2349\n",
      "Epoch 245/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1109 - val_loss: 0.2503\n",
      "Epoch 246/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1166 - val_loss: 0.2512\n",
      "Epoch 247/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1143 - val_loss: 0.2486\n",
      "Epoch 248/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1160 - val_loss: 0.2552\n",
      "Epoch 249/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1158 - val_loss: 0.2493\n",
      "Epoch 250/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1124 - val_loss: 0.2419\n",
      "Epoch 251/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1161 - val_loss: 0.2485\n",
      "Epoch 252/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1086 - val_loss: 0.2388\n",
      "Epoch 253/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1161 - val_loss: 0.2448\n",
      "Epoch 254/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1132 - val_loss: 0.2449\n",
      "Epoch 255/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1150 - val_loss: 0.2566\n",
      "Epoch 256/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1100 - val_loss: 0.2603\n",
      "Epoch 257/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1148 - val_loss: 0.2515\n",
      "Epoch 258/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1078 - val_loss: 0.2497\n",
      "Epoch 259/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1089 - val_loss: 0.2487\n",
      "Epoch 260/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1093 - val_loss: 0.2522\n",
      "Epoch 261/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1138 - val_loss: 0.2548\n",
      "Epoch 262/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1161 - val_loss: 0.2580\n",
      "Epoch 263/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1107 - val_loss: 0.2497\n",
      "Epoch 264/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1175 - val_loss: 0.2601\n",
      "Epoch 265/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1099 - val_loss: 0.2521\n",
      "Epoch 266/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1124 - val_loss: 0.2554\n",
      "Epoch 267/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1149 - val_loss: 0.2487\n",
      "Epoch 268/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1169 - val_loss: 0.2522\n",
      "Epoch 269/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1050 - val_loss: 0.2468\n",
      "Epoch 270/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1158 - val_loss: 0.2560\n",
      "Epoch 271/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1137 - val_loss: 0.2472\n",
      "Epoch 272/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1295 - val_loss: 0.2437\n",
      "Epoch 273/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1180 - val_loss: 0.2693\n",
      "Epoch 274/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1214 - val_loss: 0.2624\n",
      "Epoch 275/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1208 - val_loss: 0.2534\n",
      "Epoch 276/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1112 - val_loss: 0.2481\n",
      "Epoch 277/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1048 - val_loss: 0.2562\n",
      "Epoch 278/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1100 - val_loss: 0.2582\n",
      "Epoch 279/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1118 - val_loss: 0.2624\n",
      "Epoch 280/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1192 - val_loss: 0.2546\n",
      "Epoch 281/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1119 - val_loss: 0.2496\n",
      "Epoch 282/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1157 - val_loss: 0.2542\n",
      "Epoch 283/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1124 - val_loss: 0.2591\n",
      "Epoch 284/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1181 - val_loss: 0.2568\n",
      "Epoch 285/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1075 - val_loss: 0.2570\n",
      "Epoch 286/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1191 - val_loss: 0.2657\n",
      "Epoch 287/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1089 - val_loss: 0.2592\n",
      "Epoch 288/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1122 - val_loss: 0.2624\n",
      "Epoch 289/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1103 - val_loss: 0.2570\n",
      "Epoch 290/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1026 - val_loss: 0.2560\n",
      "Epoch 291/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1140 - val_loss: 0.2604\n",
      "Epoch 292/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1112 - val_loss: 0.2598\n",
      "Epoch 293/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1094 - val_loss: 0.2573\n",
      "Epoch 294/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1073 - val_loss: 0.2661\n",
      "Epoch 295/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1091 - val_loss: 0.2521\n",
      "Epoch 296/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1095 - val_loss: 0.2680\n",
      "Epoch 297/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1115 - val_loss: 0.2626\n",
      "Epoch 298/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1111 - val_loss: 0.2614\n",
      "Epoch 299/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1087 - val_loss: 0.2463\n",
      "Epoch 300/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1118 - val_loss: 0.2605\n",
      "Epoch 301/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1128 - val_loss: 0.2596\n",
      "Epoch 302/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1097 - val_loss: 0.2653\n",
      "Epoch 303/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1045 - val_loss: 0.2579\n",
      "Epoch 304/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1052 - val_loss: 0.2632\n",
      "Epoch 305/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1066 - val_loss: 0.2628\n",
      "Epoch 306/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1196 - val_loss: 0.2555\n",
      "Epoch 307/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1014 - val_loss: 0.2696\n",
      "Epoch 308/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1028 - val_loss: 0.2571\n",
      "Epoch 309/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1176 - val_loss: 0.2587\n",
      "Epoch 310/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1079 - val_loss: 0.2613\n",
      "Epoch 311/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1030 - val_loss: 0.2452\n",
      "Epoch 312/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1097 - val_loss: 0.2625\n",
      "Epoch 313/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1060 - val_loss: 0.2598\n",
      "Epoch 314/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1104 - val_loss: 0.2477\n",
      "Epoch 315/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1104 - val_loss: 0.2630\n",
      "Epoch 316/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1126 - val_loss: 0.2602\n",
      "Epoch 317/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1006 - val_loss: 0.2637\n",
      "Epoch 318/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1043 - val_loss: 0.2622\n",
      "Epoch 319/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1138 - val_loss: 0.2521\n",
      "Epoch 320/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1070 - val_loss: 0.2604\n",
      "Epoch 321/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1061 - val_loss: 0.2585\n",
      "Epoch 322/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1022 - val_loss: 0.2643\n",
      "Epoch 323/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1019 - val_loss: 0.2553\n",
      "Epoch 324/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1056 - val_loss: 0.2624\n",
      "Epoch 325/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1075 - val_loss: 0.2590\n",
      "Epoch 326/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1092 - val_loss: 0.2677\n",
      "Epoch 327/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1004 - val_loss: 0.2615\n",
      "Epoch 328/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1053 - val_loss: 0.2685\n",
      "Epoch 329/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1060 - val_loss: 0.2644\n",
      "Epoch 330/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1035 - val_loss: 0.2694\n",
      "Epoch 331/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1053 - val_loss: 0.2503\n",
      "Epoch 332/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1140 - val_loss: 0.2655\n",
      "Epoch 333/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1029 - val_loss: 0.2567\n",
      "Epoch 334/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1111 - val_loss: 0.2629\n",
      "Epoch 335/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1004 - val_loss: 0.2627\n",
      "Epoch 336/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1074 - val_loss: 0.2672\n",
      "Epoch 337/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1004 - val_loss: 0.2660\n",
      "Epoch 338/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0967 - val_loss: 0.2606\n",
      "Epoch 339/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1002 - val_loss: 0.2620\n",
      "Epoch 340/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1088 - val_loss: 0.2590\n",
      "Epoch 341/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0981 - val_loss: 0.2653\n",
      "Epoch 342/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1019 - val_loss: 0.2623\n",
      "Epoch 343/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0996 - val_loss: 0.2652\n",
      "Epoch 344/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0902 - val_loss: 0.2664\n",
      "Epoch 345/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0965 - val_loss: 0.2620\n",
      "Epoch 346/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0974 - val_loss: 0.2664\n",
      "Epoch 347/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1057 - val_loss: 0.2596\n",
      "Epoch 348/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1048 - val_loss: 0.2714\n",
      "Epoch 349/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1020 - val_loss: 0.2653\n",
      "Epoch 350/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1045 - val_loss: 0.2578\n",
      "Epoch 351/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1021 - val_loss: 0.2636\n",
      "Epoch 352/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1041 - val_loss: 0.2642\n",
      "Epoch 353/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0959 - val_loss: 0.2707\n",
      "Epoch 354/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1014 - val_loss: 0.2653\n",
      "Epoch 355/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0936 - val_loss: 0.2700\n",
      "Epoch 356/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0979 - val_loss: 0.2645\n",
      "Epoch 357/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0927 - val_loss: 0.2559\n",
      "Epoch 358/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1028 - val_loss: 0.2597\n",
      "Epoch 359/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0984 - val_loss: 0.2589\n",
      "Epoch 360/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0969 - val_loss: 0.2593\n",
      "Epoch 361/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1039 - val_loss: 0.2672\n",
      "Epoch 362/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0997 - val_loss: 0.2656\n",
      "Epoch 363/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1020 - val_loss: 0.2702\n",
      "Epoch 364/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0954 - val_loss: 0.2566\n",
      "Epoch 365/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0951 - val_loss: 0.2657\n",
      "Epoch 366/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0940 - val_loss: 0.2557\n",
      "Epoch 367/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1053 - val_loss: 0.2709\n",
      "Epoch 368/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1011 - val_loss: 0.2650\n",
      "Epoch 369/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1064 - val_loss: 0.2686\n",
      "Epoch 370/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0968 - val_loss: 0.2607\n",
      "Epoch 371/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0973 - val_loss: 0.2653\n",
      "Epoch 372/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0926 - val_loss: 0.2714\n",
      "Epoch 373/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0963 - val_loss: 0.2715\n",
      "Epoch 374/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0893 - val_loss: 0.2715\n",
      "Epoch 375/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0942 - val_loss: 0.2709\n",
      "Epoch 376/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0942 - val_loss: 0.2710\n",
      "Epoch 377/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0965 - val_loss: 0.2669\n",
      "Epoch 378/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1029 - val_loss: 0.2656\n",
      "Epoch 379/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1076 - val_loss: 0.2738\n",
      "Epoch 380/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0904 - val_loss: 0.2657\n",
      "Epoch 381/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1033 - val_loss: 0.2729\n",
      "Epoch 382/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0881 - val_loss: 0.2714\n",
      "Epoch 383/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0971 - val_loss: 0.2749\n",
      "Epoch 384/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0895 - val_loss: 0.2740\n",
      "Epoch 385/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0956 - val_loss: 0.2664\n",
      "Epoch 386/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0975 - val_loss: 0.2662\n",
      "Epoch 387/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0919 - val_loss: 0.2739\n",
      "Epoch 388/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1020 - val_loss: 0.2687\n",
      "Epoch 389/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0890 - val_loss: 0.2699\n",
      "Epoch 390/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1013 - val_loss: 0.2755\n",
      "Epoch 391/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0913 - val_loss: 0.2641\n",
      "Epoch 392/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0981 - val_loss: 0.2720\n",
      "Epoch 393/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1034 - val_loss: 0.2744\n",
      "Epoch 394/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0959 - val_loss: 0.2708\n",
      "Epoch 395/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0920 - val_loss: 0.2668\n",
      "Epoch 396/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0953 - val_loss: 0.2720\n",
      "Epoch 397/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0949 - val_loss: 0.2678\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0923 - val_loss: 0.2710\n",
      "Epoch 399/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0868 - val_loss: 0.2655\n",
      "Epoch 400/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0974 - val_loss: 0.2643\n",
      "Epoch 401/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0925 - val_loss: 0.2650\n",
      "Epoch 402/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0909 - val_loss: 0.2704\n",
      "Epoch 403/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0915 - val_loss: 0.2701\n",
      "Epoch 404/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0958 - val_loss: 0.2760\n",
      "Epoch 405/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0958 - val_loss: 0.2699\n",
      "Epoch 406/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0920 - val_loss: 0.2695\n",
      "Epoch 407/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0945 - val_loss: 0.2734\n",
      "Epoch 408/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0887 - val_loss: 0.2723\n",
      "Epoch 409/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0882 - val_loss: 0.2733\n",
      "Epoch 410/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0903 - val_loss: 0.2744\n",
      "Epoch 411/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0978 - val_loss: 0.2770\n",
      "Epoch 412/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0948 - val_loss: 0.2609\n",
      "Epoch 413/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0918 - val_loss: 0.2753\n",
      "Epoch 414/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0954 - val_loss: 0.2680\n",
      "Epoch 415/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.1034 - val_loss: 0.2682\n",
      "Epoch 416/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0802 - val_loss: 0.2658\n",
      "Epoch 417/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0990 - val_loss: 0.2745\n",
      "Epoch 418/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.1013 - val_loss: 0.2716\n",
      "Epoch 419/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0923 - val_loss: 0.2702\n",
      "Epoch 420/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0948 - val_loss: 0.2666\n",
      "Epoch 421/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0907 - val_loss: 0.2632\n",
      "Epoch 422/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0947 - val_loss: 0.2778\n",
      "Epoch 423/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0795 - val_loss: 0.2683\n",
      "Epoch 424/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0846 - val_loss: 0.2758\n",
      "Epoch 425/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0883 - val_loss: 0.2657\n",
      "Epoch 426/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0927 - val_loss: 0.2722\n",
      "Epoch 427/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0870 - val_loss: 0.2709\n",
      "Epoch 428/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0816 - val_loss: 0.2766\n",
      "Epoch 429/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0837 - val_loss: 0.2706\n",
      "Epoch 430/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0859 - val_loss: 0.2710\n",
      "Epoch 431/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0898 - val_loss: 0.2671\n",
      "Epoch 432/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0911 - val_loss: 0.2655\n",
      "Epoch 433/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.1031 - val_loss: 0.2717\n",
      "Epoch 434/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0798 - val_loss: 0.2725\n",
      "Epoch 435/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0962 - val_loss: 0.2684\n",
      "Epoch 436/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0915 - val_loss: 0.2756\n",
      "Epoch 437/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0948 - val_loss: 0.2669\n",
      "Epoch 438/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0854 - val_loss: 0.2663\n",
      "Epoch 439/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0915 - val_loss: 0.2730\n",
      "Epoch 440/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0872 - val_loss: 0.2697\n",
      "Epoch 441/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0855 - val_loss: 0.2654\n",
      "Epoch 442/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0896 - val_loss: 0.2694\n",
      "Epoch 443/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0911 - val_loss: 0.2621\n",
      "Epoch 444/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0914 - val_loss: 0.2682\n",
      "Epoch 445/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0800 - val_loss: 0.2731\n",
      "Epoch 446/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0869 - val_loss: 0.2721\n",
      "Epoch 447/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0880 - val_loss: 0.2721\n",
      "Epoch 448/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0823 - val_loss: 0.2721\n",
      "Epoch 449/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0983 - val_loss: 0.2743\n",
      "Epoch 450/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0842 - val_loss: 0.2808\n",
      "Epoch 451/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0869 - val_loss: 0.2721\n",
      "Epoch 452/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0864 - val_loss: 0.2695\n",
      "Epoch 453/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0826 - val_loss: 0.2631\n",
      "Epoch 454/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0886 - val_loss: 0.2774\n",
      "Epoch 455/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0845 - val_loss: 0.2754\n",
      "Epoch 456/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0881 - val_loss: 0.2513\n",
      "Epoch 457/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0878 - val_loss: 0.2755\n",
      "Epoch 458/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0854 - val_loss: 0.2680\n",
      "Epoch 459/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0796 - val_loss: 0.2682\n",
      "Epoch 460/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0871 - val_loss: 0.2722\n",
      "Epoch 461/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0898 - val_loss: 0.2615\n",
      "Epoch 462/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0803 - val_loss: 0.2756\n",
      "Epoch 463/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0809 - val_loss: 0.2765\n",
      "Epoch 464/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0823 - val_loss: 0.2705\n",
      "Epoch 465/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0837 - val_loss: 0.2751\n",
      "Epoch 466/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0857 - val_loss: 0.2742\n",
      "Epoch 467/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0917 - val_loss: 0.2695\n",
      "Epoch 468/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0804 - val_loss: 0.2756\n",
      "Epoch 469/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0848 - val_loss: 0.2771\n",
      "Epoch 470/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0848 - val_loss: 0.2878\n",
      "Epoch 471/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0905 - val_loss: 0.2782\n",
      "Epoch 472/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0873 - val_loss: 0.2766\n",
      "Epoch 473/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0895 - val_loss: 0.2770\n",
      "Epoch 474/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0828 - val_loss: 0.2794\n",
      "Epoch 475/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0890 - val_loss: 0.2734\n",
      "Epoch 476/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0813 - val_loss: 0.2686\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0777 - val_loss: 0.2719\n",
      "Epoch 478/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0830 - val_loss: 0.2804\n",
      "Epoch 479/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0883 - val_loss: 0.2754\n",
      "Epoch 480/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0829 - val_loss: 0.2642\n",
      "Epoch 481/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0803 - val_loss: 0.2757\n",
      "Epoch 482/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0862 - val_loss: 0.2825\n",
      "Epoch 483/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0856 - val_loss: 0.2775\n",
      "Epoch 484/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0751 - val_loss: 0.2747\n",
      "Epoch 485/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0825 - val_loss: 0.2741\n",
      "Epoch 486/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0758 - val_loss: 0.2812\n",
      "Epoch 487/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0814 - val_loss: 0.2797\n",
      "Epoch 488/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0781 - val_loss: 0.2724\n",
      "Epoch 489/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0838 - val_loss: 0.2696\n",
      "Epoch 490/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0792 - val_loss: 0.2890\n",
      "Epoch 491/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0843 - val_loss: 0.2730\n",
      "Epoch 492/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0822 - val_loss: 0.2814\n",
      "Epoch 493/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0809 - val_loss: 0.2852\n",
      "Epoch 494/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0820 - val_loss: 0.2782\n",
      "Epoch 495/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0758 - val_loss: 0.2769\n",
      "Epoch 496/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0816 - val_loss: 0.2773\n",
      "Epoch 497/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0860 - val_loss: 0.2765\n",
      "Epoch 498/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0781 - val_loss: 0.2753\n",
      "Epoch 499/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0714 - val_loss: 0.2694\n",
      "Epoch 500/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0748 - val_loss: 0.2808\n",
      "Epoch 501/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0713 - val_loss: 0.2771\n",
      "Epoch 502/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0793 - val_loss: 0.2831\n",
      "Epoch 503/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0746 - val_loss: 0.2755\n",
      "Epoch 504/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0691 - val_loss: 0.2736\n",
      "Epoch 505/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0796 - val_loss: 0.2830\n",
      "Epoch 506/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0779 - val_loss: 0.2802\n",
      "Epoch 507/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0825 - val_loss: 0.2699\n",
      "Epoch 508/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0772 - val_loss: 0.2766\n",
      "Epoch 509/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0835 - val_loss: 0.2797\n",
      "Epoch 510/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0853 - val_loss: 0.2759\n",
      "Epoch 511/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0752 - val_loss: 0.2753\n",
      "Epoch 512/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0760 - val_loss: 0.2785\n",
      "Epoch 513/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0782 - val_loss: 0.2790\n",
      "Epoch 514/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0708 - val_loss: 0.2782\n",
      "Epoch 515/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0746 - val_loss: 0.2838\n",
      "Epoch 516/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0852 - val_loss: 0.2871\n",
      "Epoch 517/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0830 - val_loss: 0.2849\n",
      "Epoch 518/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0770 - val_loss: 0.2855\n",
      "Epoch 519/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0718 - val_loss: 0.2812\n",
      "Epoch 520/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0776 - val_loss: 0.2830\n",
      "Epoch 521/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0755 - val_loss: 0.2867\n",
      "Epoch 522/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0810 - val_loss: 0.2883\n",
      "Epoch 523/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0781 - val_loss: 0.2824\n",
      "Epoch 524/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0719 - val_loss: 0.2841\n",
      "Epoch 525/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0713 - val_loss: 0.2802\n",
      "Epoch 526/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0756 - val_loss: 0.2856\n",
      "Epoch 527/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0713 - val_loss: 0.2784\n",
      "Epoch 528/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0732 - val_loss: 0.2831\n",
      "Epoch 529/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0755 - val_loss: 0.2808\n",
      "Epoch 530/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0695 - val_loss: 0.2846\n",
      "Epoch 531/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0736 - val_loss: 0.2946\n",
      "Epoch 532/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0827 - val_loss: 0.2819\n",
      "Epoch 533/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0717 - val_loss: 0.2802\n",
      "Epoch 534/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0782 - val_loss: 0.2868\n",
      "Epoch 535/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0759 - val_loss: 0.2820\n",
      "Epoch 536/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0728 - val_loss: 0.2835\n",
      "Epoch 537/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0749 - val_loss: 0.2863\n",
      "Epoch 538/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0768 - val_loss: 0.2869\n",
      "Epoch 539/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0753 - val_loss: 0.2862\n",
      "Epoch 540/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0778 - val_loss: 0.2830\n",
      "Epoch 541/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0641 - val_loss: 0.2893\n",
      "Epoch 542/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0735 - val_loss: 0.2907\n",
      "Epoch 543/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0742 - val_loss: 0.2839\n",
      "Epoch 544/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0659 - val_loss: 0.2889\n",
      "Epoch 545/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0679 - val_loss: 0.2886\n",
      "Epoch 546/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0704 - val_loss: 0.2854\n",
      "Epoch 547/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0832 - val_loss: 0.2861\n",
      "Epoch 548/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0763 - val_loss: 0.2829\n",
      "Epoch 549/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0729 - val_loss: 0.2891\n",
      "Epoch 550/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0780 - val_loss: 0.2874\n",
      "Epoch 551/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0741 - val_loss: 0.2856\n",
      "Epoch 552/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0735 - val_loss: 0.2888\n",
      "Epoch 553/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0686 - val_loss: 0.2914\n",
      "Epoch 554/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0719 - val_loss: 0.2968\n",
      "Epoch 555/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0709 - val_loss: 0.2923\n",
      "Epoch 556/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0750 - val_loss: 0.2910\n",
      "Epoch 557/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0703 - val_loss: 0.2886\n",
      "Epoch 558/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0749 - val_loss: 0.2878\n",
      "Epoch 559/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0645 - val_loss: 0.2937\n",
      "Epoch 560/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0680 - val_loss: 0.2803\n",
      "Epoch 561/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0797 - val_loss: 0.2928\n",
      "Epoch 562/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0742 - val_loss: 0.2886\n",
      "Epoch 563/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0747 - val_loss: 0.2920\n",
      "Epoch 564/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0745 - val_loss: 0.2902\n",
      "Epoch 565/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0722 - val_loss: 0.2959\n",
      "Epoch 566/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0631 - val_loss: 0.2903\n",
      "Epoch 567/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0651 - val_loss: 0.2833\n",
      "Epoch 568/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0699 - val_loss: 0.2922\n",
      "Epoch 569/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0735 - val_loss: 0.2904\n",
      "Epoch 570/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0662 - val_loss: 0.2961\n",
      "Epoch 571/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0689 - val_loss: 0.2892\n",
      "Epoch 572/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0736 - val_loss: 0.2849\n",
      "Epoch 573/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0634 - val_loss: 0.2833\n",
      "Epoch 574/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0704 - val_loss: 0.2891\n",
      "Epoch 575/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0635 - val_loss: 0.2906\n",
      "Epoch 576/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0710 - val_loss: 0.3017\n",
      "Epoch 577/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0678 - val_loss: 0.2888\n",
      "Epoch 578/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0740 - val_loss: 0.2979\n",
      "Epoch 579/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0717 - val_loss: 0.2882\n",
      "Epoch 580/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0723 - val_loss: 0.2921\n",
      "Epoch 581/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0674 - val_loss: 0.2825\n",
      "Epoch 582/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0719 - val_loss: 0.2895\n",
      "Epoch 583/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0762 - val_loss: 0.2920\n",
      "Epoch 584/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0679 - val_loss: 0.2836\n",
      "Epoch 585/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0716 - val_loss: 0.2980\n",
      "Epoch 586/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0673 - val_loss: 0.2948\n",
      "Epoch 587/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0718 - val_loss: 0.2888\n",
      "Epoch 588/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0735 - val_loss: 0.2994\n",
      "Epoch 589/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0672 - val_loss: 0.2840\n",
      "Epoch 590/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0706 - val_loss: 0.2952\n",
      "Epoch 591/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0649 - val_loss: 0.2984\n",
      "Epoch 592/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0712 - val_loss: 0.2975\n",
      "Epoch 593/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0675 - val_loss: 0.2982\n",
      "Epoch 594/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0695 - val_loss: 0.2857\n",
      "Epoch 595/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0666 - val_loss: 0.2914\n",
      "Epoch 596/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0626 - val_loss: 0.2955\n",
      "Epoch 597/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0627 - val_loss: 0.2910\n",
      "Epoch 598/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0667 - val_loss: 0.3036\n",
      "Epoch 599/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0731 - val_loss: 0.3004\n",
      "Epoch 600/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0618 - val_loss: 0.2873\n",
      "Epoch 601/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0619 - val_loss: 0.3017\n",
      "Epoch 602/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0676 - val_loss: 0.2982\n",
      "Epoch 603/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0602 - val_loss: 0.2963\n",
      "Epoch 604/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0598 - val_loss: 0.3088\n",
      "Epoch 605/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0664 - val_loss: 0.3013\n",
      "Epoch 606/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0685 - val_loss: 0.2892\n",
      "Epoch 607/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0625 - val_loss: 0.2925\n",
      "Epoch 608/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0721 - val_loss: 0.2941\n",
      "Epoch 609/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0641 - val_loss: 0.3012\n",
      "Epoch 610/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0641 - val_loss: 0.2965\n",
      "Epoch 611/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0698 - val_loss: 0.2845\n",
      "Epoch 612/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0736 - val_loss: 0.2921\n",
      "Epoch 613/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0579 - val_loss: 0.2957\n",
      "Epoch 614/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0655 - val_loss: 0.2914\n",
      "Epoch 615/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0695 - val_loss: 0.3014\n",
      "Epoch 616/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0583 - val_loss: 0.2948\n",
      "Epoch 617/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0584 - val_loss: 0.2943\n",
      "Epoch 618/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0693 - val_loss: 0.3031\n",
      "Epoch 619/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0715 - val_loss: 0.2992\n",
      "Epoch 620/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0687 - val_loss: 0.2950\n",
      "Epoch 621/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0678 - val_loss: 0.2909\n",
      "Epoch 622/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.0645 - val_loss: 0.2899\n",
      "Epoch 623/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0620 - val_loss: 0.2934\n",
      "Epoch 624/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0599 - val_loss: 0.3015\n",
      "Epoch 625/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0580 - val_loss: 0.3058\n",
      "Epoch 626/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0667 - val_loss: 0.3060\n",
      "Epoch 627/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0652 - val_loss: 0.2978\n",
      "Epoch 628/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0663 - val_loss: 0.2921\n",
      "Epoch 629/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0728 - val_loss: 0.2937\n",
      "Epoch 630/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0696 - val_loss: 0.3098\n",
      "Epoch 631/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0615 - val_loss: 0.3047\n",
      "Epoch 632/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0655 - val_loss: 0.2936\n",
      "Epoch 633/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0622 - val_loss: 0.3016\n",
      "Epoch 634/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0652 - val_loss: 0.3008\n",
      "Epoch 635/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0603 - val_loss: 0.3065\n",
      "Epoch 636/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0666 - val_loss: 0.3036\n",
      "Epoch 637/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0645 - val_loss: 0.2992\n",
      "Epoch 638/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0624 - val_loss: 0.2942\n",
      "Epoch 639/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0542 - val_loss: 0.2984\n",
      "Epoch 640/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0613 - val_loss: 0.3047\n",
      "Epoch 641/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0593 - val_loss: 0.3047\n",
      "Epoch 642/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0577 - val_loss: 0.2920\n",
      "Epoch 643/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0604 - val_loss: 0.2993\n",
      "Epoch 644/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0634 - val_loss: 0.3097\n",
      "Epoch 645/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0666 - val_loss: 0.2998\n",
      "Epoch 646/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0591 - val_loss: 0.3112\n",
      "Epoch 647/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0581 - val_loss: 0.2963\n",
      "Epoch 648/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0629 - val_loss: 0.2844\n",
      "Epoch 649/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0632 - val_loss: 0.3063\n",
      "Epoch 650/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0683 - val_loss: 0.2871\n",
      "Epoch 651/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0673 - val_loss: 0.3038\n",
      "Epoch 652/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0669 - val_loss: 0.2910\n",
      "Epoch 653/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0638 - val_loss: 0.3097\n",
      "Epoch 654/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0619 - val_loss: 0.2986\n",
      "Epoch 655/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0621 - val_loss: 0.3139\n",
      "Epoch 656/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0614 - val_loss: 0.3077\n",
      "Epoch 657/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0599 - val_loss: 0.3042\n",
      "Epoch 658/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0701 - val_loss: 0.3132\n",
      "Epoch 659/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0613 - val_loss: 0.3113\n",
      "Epoch 660/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0698 - val_loss: 0.3130\n",
      "Epoch 661/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0617 - val_loss: 0.3033\n",
      "Epoch 662/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0578 - val_loss: 0.3117\n",
      "Epoch 663/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0586 - val_loss: 0.2908\n",
      "Epoch 664/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0600 - val_loss: 0.3062\n",
      "Epoch 665/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0580 - val_loss: 0.3094\n",
      "Epoch 666/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0584 - val_loss: 0.3049\n",
      "Epoch 667/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0570 - val_loss: 0.2977\n",
      "Epoch 668/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0669 - val_loss: 0.2913\n",
      "Epoch 669/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0662 - val_loss: 0.3116\n",
      "Epoch 670/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0675 - val_loss: 0.3187\n",
      "Epoch 671/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0579 - val_loss: 0.3029\n",
      "Epoch 672/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0645 - val_loss: 0.3134\n",
      "Epoch 673/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0594 - val_loss: 0.3140\n",
      "Epoch 674/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0577 - val_loss: 0.3082\n",
      "Epoch 675/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0604 - val_loss: 0.3068\n",
      "Epoch 676/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0579 - val_loss: 0.3059\n",
      "Epoch 677/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0620 - val_loss: 0.3055\n",
      "Epoch 678/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0547 - val_loss: 0.3057\n",
      "Epoch 679/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0613 - val_loss: 0.3032\n",
      "Epoch 680/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0579 - val_loss: 0.3121\n",
      "Epoch 681/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0557 - val_loss: 0.3146\n",
      "Epoch 682/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0667 - val_loss: 0.3011\n",
      "Epoch 683/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0622 - val_loss: 0.3151\n",
      "Epoch 684/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0605 - val_loss: 0.3091\n",
      "Epoch 685/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0601 - val_loss: 0.3019\n",
      "Epoch 686/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0559 - val_loss: 0.3140\n",
      "Epoch 687/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0563 - val_loss: 0.3146\n",
      "Epoch 688/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0601 - val_loss: 0.3157\n",
      "Epoch 689/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0585 - val_loss: 0.3069\n",
      "Epoch 690/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0625 - val_loss: 0.3106\n",
      "Epoch 691/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0544 - val_loss: 0.3015\n",
      "Epoch 692/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0535 - val_loss: 0.3112\n",
      "Epoch 693/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0560 - val_loss: 0.3150\n",
      "Epoch 694/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0588 - val_loss: 0.3179\n",
      "Epoch 695/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0574 - val_loss: 0.3173\n",
      "Epoch 696/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0596 - val_loss: 0.3100\n",
      "Epoch 697/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0505 - val_loss: 0.3121\n",
      "Epoch 698/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0610 - val_loss: 0.3180\n",
      "Epoch 699/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0568 - val_loss: 0.3041\n",
      "Epoch 700/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0625 - val_loss: 0.3080\n",
      "Epoch 701/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0604 - val_loss: 0.3140\n",
      "Epoch 702/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0601 - val_loss: 0.3108\n",
      "Epoch 703/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0550 - val_loss: 0.3185\n",
      "Epoch 704/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0520 - val_loss: 0.3154\n",
      "Epoch 705/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0528 - val_loss: 0.3044\n",
      "Epoch 706/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0518 - val_loss: 0.3149\n",
      "Epoch 707/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0513 - val_loss: 0.3094\n",
      "Epoch 708/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0565 - val_loss: 0.3082\n",
      "Epoch 709/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0585 - val_loss: 0.3129\n",
      "Epoch 710/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0629 - val_loss: 0.3145\n",
      "Epoch 711/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0537 - val_loss: 0.3178\n",
      "Epoch 712/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0584 - val_loss: 0.3161\n",
      "Epoch 713/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0522 - val_loss: 0.3214\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0554 - val_loss: 0.3078\n",
      "Epoch 715/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0556 - val_loss: 0.3230\n",
      "Epoch 716/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0550 - val_loss: 0.3122\n",
      "Epoch 717/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0511 - val_loss: 0.3206\n",
      "Epoch 718/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0529 - val_loss: 0.3122\n",
      "Epoch 719/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0568 - val_loss: 0.2958\n",
      "Epoch 720/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0571 - val_loss: 0.3171\n",
      "Epoch 721/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0610 - val_loss: 0.3151\n",
      "Epoch 722/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0624 - val_loss: 0.3159\n",
      "Epoch 723/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0525 - val_loss: 0.3217\n",
      "Epoch 724/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0545 - val_loss: 0.3118\n",
      "Epoch 725/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0531 - val_loss: 0.3285\n",
      "Epoch 726/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0583 - val_loss: 0.3214\n",
      "Epoch 727/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0624 - val_loss: 0.3032\n",
      "Epoch 728/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0546 - val_loss: 0.3048\n",
      "Epoch 729/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0500 - val_loss: 0.3224\n",
      "Epoch 730/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0522 - val_loss: 0.3227\n",
      "Epoch 731/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0627 - val_loss: 0.3196\n",
      "Epoch 732/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0517 - val_loss: 0.3140\n",
      "Epoch 733/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0527 - val_loss: 0.3247\n",
      "Epoch 734/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0469 - val_loss: 0.3110\n",
      "Epoch 735/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0518 - val_loss: 0.3161\n",
      "Epoch 736/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0566 - val_loss: 0.2976\n",
      "Epoch 737/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0517 - val_loss: 0.3166\n",
      "Epoch 738/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0525 - val_loss: 0.3085\n",
      "Epoch 739/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0533 - val_loss: 0.3156\n",
      "Epoch 740/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0516 - val_loss: 0.3231\n",
      "Epoch 741/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0563 - val_loss: 0.3052\n",
      "Epoch 742/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0492 - val_loss: 0.3200\n",
      "Epoch 743/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0660 - val_loss: 0.3248\n",
      "Epoch 744/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0516 - val_loss: 0.3135\n",
      "Epoch 745/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0565 - val_loss: 0.3097\n",
      "Epoch 746/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0538 - val_loss: 0.3189\n",
      "Epoch 747/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0485 - val_loss: 0.3136\n",
      "Epoch 748/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0566 - val_loss: 0.3272\n",
      "Epoch 749/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0547 - val_loss: 0.3167\n",
      "Epoch 750/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0528 - val_loss: 0.3175\n",
      "Epoch 751/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0550 - val_loss: 0.3071\n",
      "Epoch 752/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0523 - val_loss: 0.3233\n",
      "Epoch 753/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0464 - val_loss: 0.3019\n",
      "Epoch 754/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0524 - val_loss: 0.3153\n",
      "Epoch 755/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0560 - val_loss: 0.3163\n",
      "Epoch 756/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0617 - val_loss: 0.3122\n",
      "Epoch 757/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0489 - val_loss: 0.3164\n",
      "Epoch 758/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0519 - val_loss: 0.3267\n",
      "Epoch 759/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0669 - val_loss: 0.3199\n",
      "Epoch 760/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0525 - val_loss: 0.3098\n",
      "Epoch 761/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0544 - val_loss: 0.3053\n",
      "Epoch 762/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0524 - val_loss: 0.3151\n",
      "Epoch 763/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0537 - val_loss: 0.3242\n",
      "Epoch 764/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0505 - val_loss: 0.3080\n",
      "Epoch 765/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0616 - val_loss: 0.3051\n",
      "Epoch 766/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0588 - val_loss: 0.3226\n",
      "Epoch 767/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0509 - val_loss: 0.3025\n",
      "Epoch 768/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0539 - val_loss: 0.3001\n",
      "Epoch 769/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0496 - val_loss: 0.3067\n",
      "Epoch 770/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0466 - val_loss: 0.3141\n",
      "Epoch 771/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0498 - val_loss: 0.3207\n",
      "Epoch 772/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0487 - val_loss: 0.2953\n",
      "Epoch 773/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0508 - val_loss: 0.3137\n",
      "Epoch 774/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0603 - val_loss: 0.3149\n",
      "Epoch 775/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0509 - val_loss: 0.3227\n",
      "Epoch 776/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0557 - val_loss: 0.3094\n",
      "Epoch 777/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0679 - val_loss: 0.3222\n",
      "Epoch 778/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0463 - val_loss: 0.3230\n",
      "Epoch 779/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0503 - val_loss: 0.3156\n",
      "Epoch 780/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0466 - val_loss: 0.3062\n",
      "Epoch 781/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0450 - val_loss: 0.3182\n",
      "Epoch 782/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0491 - val_loss: 0.3189\n",
      "Epoch 783/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0496 - val_loss: 0.3217\n",
      "Epoch 784/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0528 - val_loss: 0.3068\n",
      "Epoch 785/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0464 - val_loss: 0.3226\n",
      "Epoch 786/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0491 - val_loss: 0.3148\n",
      "Epoch 787/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0521 - val_loss: 0.3021\n",
      "Epoch 788/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0546 - val_loss: 0.3195\n",
      "Epoch 789/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0469 - val_loss: 0.3158\n",
      "Epoch 790/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0485 - val_loss: 0.3112\n",
      "Epoch 791/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0577 - val_loss: 0.3055\n",
      "Epoch 792/1000\n",
      "57/57 [==============================] - 2s 38ms/step - loss: 0.0481 - val_loss: 0.3159\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0467 - val_loss: 0.2994\n",
      "Epoch 794/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0525 - val_loss: 0.3112\n",
      "Epoch 795/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0494 - val_loss: 0.3156\n",
      "Epoch 796/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0504 - val_loss: 0.3163\n",
      "Epoch 797/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0487 - val_loss: 0.3252\n",
      "Epoch 798/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0503 - val_loss: 0.3222\n",
      "Epoch 799/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0553 - val_loss: 0.3065\n",
      "Epoch 800/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0484 - val_loss: 0.3296\n",
      "Epoch 801/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0496 - val_loss: 0.3059\n",
      "Epoch 802/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0505 - val_loss: 0.3115\n",
      "Epoch 803/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0508 - val_loss: 0.3118\n",
      "Epoch 804/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0460 - val_loss: 0.3203\n",
      "Epoch 805/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0498 - val_loss: 0.2997\n",
      "Epoch 806/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0479 - val_loss: 0.3184\n",
      "Epoch 807/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0518 - val_loss: 0.3245\n",
      "Epoch 808/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0522 - val_loss: 0.3107\n",
      "Epoch 809/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0482 - val_loss: 0.3159\n",
      "Epoch 810/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0535 - val_loss: 0.2984\n",
      "Epoch 811/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0503 - val_loss: 0.3172\n",
      "Epoch 812/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0491 - val_loss: 0.3233\n",
      "Epoch 813/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0483 - val_loss: 0.3190\n",
      "Epoch 814/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0497 - val_loss: 0.3167\n",
      "Epoch 815/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0454 - val_loss: 0.3062\n",
      "Epoch 816/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0482 - val_loss: 0.3046\n",
      "Epoch 817/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0483 - val_loss: 0.3091\n",
      "Epoch 818/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0477 - val_loss: 0.3108\n",
      "Epoch 819/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0546 - val_loss: 0.3294\n",
      "Epoch 820/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0528 - val_loss: 0.3227\n",
      "Epoch 821/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0501 - val_loss: 0.3084\n",
      "Epoch 822/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0463 - val_loss: 0.3076\n",
      "Epoch 823/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0462 - val_loss: 0.3168\n",
      "Epoch 824/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0531 - val_loss: 0.3279\n",
      "Epoch 825/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0532 - val_loss: 0.3235\n",
      "Epoch 826/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0487 - val_loss: 0.3176\n",
      "Epoch 827/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0496 - val_loss: 0.3220\n",
      "Epoch 828/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0508 - val_loss: 0.3153\n",
      "Epoch 829/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0558 - val_loss: 0.3160\n",
      "Epoch 830/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0458 - val_loss: 0.3085\n",
      "Epoch 831/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0468 - val_loss: 0.3148\n",
      "Epoch 832/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0445 - val_loss: 0.3223\n",
      "Epoch 833/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0520 - val_loss: 0.3100\n",
      "Epoch 834/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0434 - val_loss: 0.3042\n",
      "Epoch 835/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0450 - val_loss: 0.3227\n",
      "Epoch 836/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0459 - val_loss: 0.3006\n",
      "Epoch 837/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0476 - val_loss: 0.3215\n",
      "Epoch 838/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0488 - val_loss: 0.3017\n",
      "Epoch 839/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0522 - val_loss: 0.3206\n",
      "Epoch 840/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0470 - val_loss: 0.3223\n",
      "Epoch 841/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0449 - val_loss: 0.3073\n",
      "Epoch 842/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0454 - val_loss: 0.3184\n",
      "Epoch 843/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0466 - val_loss: 0.3340\n",
      "Epoch 844/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0526 - val_loss: 0.3245\n",
      "Epoch 845/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0440 - val_loss: 0.3236\n",
      "Epoch 846/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0471 - val_loss: 0.3085\n",
      "Epoch 847/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0456 - val_loss: 0.3057\n",
      "Epoch 848/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0442 - val_loss: 0.3179\n",
      "Epoch 849/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0579 - val_loss: 0.3147\n",
      "Epoch 850/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0484 - val_loss: 0.3129\n",
      "Epoch 851/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0447 - val_loss: 0.3132\n",
      "Epoch 852/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0422 - val_loss: 0.3129\n",
      "Epoch 853/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0412 - val_loss: 0.3049\n",
      "Epoch 854/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0467 - val_loss: 0.3120\n",
      "Epoch 855/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0518 - val_loss: 0.3028\n",
      "Epoch 856/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0465 - val_loss: 0.2940\n",
      "Epoch 857/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0473 - val_loss: 0.2951\n",
      "Epoch 858/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0507 - val_loss: 0.3154\n",
      "Epoch 859/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0435 - val_loss: 0.3109\n",
      "Epoch 860/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0449 - val_loss: 0.3102\n",
      "Epoch 861/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0445 - val_loss: 0.3172\n",
      "Epoch 862/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0445 - val_loss: 0.3204\n",
      "Epoch 863/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0493 - val_loss: 0.3062\n",
      "Epoch 864/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0408 - val_loss: 0.3074\n",
      "Epoch 865/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0469 - val_loss: 0.3105\n",
      "Epoch 866/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0396 - val_loss: 0.3043\n",
      "Epoch 867/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0447 - val_loss: 0.3109\n",
      "Epoch 868/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0447 - val_loss: 0.3083\n",
      "Epoch 869/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0434 - val_loss: 0.3158\n",
      "Epoch 870/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0436 - val_loss: 0.3112\n",
      "Epoch 871/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0464 - val_loss: 0.3084\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0506 - val_loss: 0.3272\n",
      "Epoch 873/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0447 - val_loss: 0.3100\n",
      "Epoch 874/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0466 - val_loss: 0.3202\n",
      "Epoch 875/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0450 - val_loss: 0.3029\n",
      "Epoch 876/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0460 - val_loss: 0.3162\n",
      "Epoch 877/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0494 - val_loss: 0.3037\n",
      "Epoch 878/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0453 - val_loss: 0.3246\n",
      "Epoch 879/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0545 - val_loss: 0.3003\n",
      "Epoch 880/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0421 - val_loss: 0.3271\n",
      "Epoch 881/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0445 - val_loss: 0.3277\n",
      "Epoch 882/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0422 - val_loss: 0.3154\n",
      "Epoch 883/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0399 - val_loss: 0.3124\n",
      "Epoch 884/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0456 - val_loss: 0.3258\n",
      "Epoch 885/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0421 - val_loss: 0.3219\n",
      "Epoch 886/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0482 - val_loss: 0.3072\n",
      "Epoch 887/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0465 - val_loss: 0.3216\n",
      "Epoch 888/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0418 - val_loss: 0.3200\n",
      "Epoch 889/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0440 - val_loss: 0.3089\n",
      "Epoch 890/1000\n",
      "57/57 [==============================] - 2s 37ms/step - loss: 0.0399 - val_loss: 0.3071\n",
      "Epoch 891/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0434 - val_loss: 0.3243\n",
      "Epoch 892/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0421 - val_loss: 0.3161\n",
      "Epoch 893/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0462 - val_loss: 0.3223\n",
      "Epoch 894/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0447 - val_loss: 0.3166\n",
      "Epoch 895/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0373 - val_loss: 0.3253\n",
      "Epoch 896/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0454 - val_loss: 0.3139\n",
      "Epoch 897/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0406 - val_loss: 0.2989\n",
      "Epoch 898/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0486 - val_loss: 0.3243\n",
      "Epoch 899/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0445 - val_loss: 0.3029\n",
      "Epoch 900/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0422 - val_loss: 0.2996\n",
      "Epoch 901/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0524 - val_loss: 0.3053\n",
      "Epoch 902/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0422 - val_loss: 0.3033\n",
      "Epoch 903/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0454 - val_loss: 0.3082\n",
      "Epoch 904/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0505 - val_loss: 0.3159\n",
      "Epoch 905/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0383 - val_loss: 0.3079\n",
      "Epoch 906/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0401 - val_loss: 0.3209\n",
      "Epoch 907/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0402 - val_loss: 0.3000\n",
      "Epoch 908/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0467 - val_loss: 0.3208\n",
      "Epoch 909/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0409 - val_loss: 0.3116\n",
      "Epoch 910/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0413 - val_loss: 0.3116\n",
      "Epoch 911/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0405 - val_loss: 0.3074\n",
      "Epoch 912/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0421 - val_loss: 0.3141\n",
      "Epoch 913/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0410 - val_loss: 0.3023\n",
      "Epoch 914/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0371 - val_loss: 0.3098\n",
      "Epoch 915/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0484 - val_loss: 0.3054\n",
      "Epoch 916/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0404 - val_loss: 0.3068\n",
      "Epoch 917/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0443 - val_loss: 0.3183\n",
      "Epoch 918/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0386 - val_loss: 0.3079\n",
      "Epoch 919/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0441 - val_loss: 0.3029\n",
      "Epoch 920/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0361 - val_loss: 0.2970\n",
      "Epoch 921/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0445 - val_loss: 0.3083\n",
      "Epoch 922/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0420 - val_loss: 0.3015\n",
      "Epoch 923/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0426 - val_loss: 0.3204\n",
      "Epoch 924/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0403 - val_loss: 0.3081\n",
      "Epoch 925/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0442 - val_loss: 0.3064\n",
      "Epoch 926/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0427 - val_loss: 0.3105\n",
      "Epoch 927/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0428 - val_loss: 0.3332\n",
      "Epoch 928/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0423 - val_loss: 0.3105\n",
      "Epoch 929/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0404 - val_loss: 0.3183\n",
      "Epoch 930/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0459 - val_loss: 0.3100\n",
      "Epoch 931/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0426 - val_loss: 0.3157\n",
      "Epoch 932/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0382 - val_loss: 0.3190\n",
      "Epoch 933/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0391 - val_loss: 0.3121\n",
      "Epoch 934/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0435 - val_loss: 0.3196\n",
      "Epoch 935/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0366 - val_loss: 0.3227\n",
      "Epoch 936/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0403 - val_loss: 0.3168\n",
      "Epoch 937/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0415 - val_loss: 0.3098\n",
      "Epoch 938/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0415 - val_loss: 0.3235\n",
      "Epoch 939/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0431 - val_loss: 0.3316\n",
      "Epoch 940/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0393 - val_loss: 0.3209\n",
      "Epoch 941/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0387 - val_loss: 0.3153\n",
      "Epoch 942/1000\n",
      "57/57 [==============================] - 2s 35ms/step - loss: 0.0404 - val_loss: 0.3177\n",
      "Epoch 943/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0463 - val_loss: 0.3222\n",
      "Epoch 944/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0394 - val_loss: 0.3142\n",
      "Epoch 945/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0383 - val_loss: 0.3230\n",
      "Epoch 946/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0404 - val_loss: 0.3283\n",
      "Epoch 947/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0376 - val_loss: 0.3227\n",
      "Epoch 948/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0398 - val_loss: 0.3144\n",
      "Epoch 949/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0650 - val_loss: 0.3068\n",
      "Epoch 950/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0403 - val_loss: 0.3266\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0442 - val_loss: 0.3198\n",
      "Epoch 952/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0418 - val_loss: 0.3178\n",
      "Epoch 953/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0377 - val_loss: 0.3006\n",
      "Epoch 954/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0401 - val_loss: 0.3048\n",
      "Epoch 955/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0387 - val_loss: 0.3370\n",
      "Epoch 956/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0427 - val_loss: 0.3080\n",
      "Epoch 957/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0376 - val_loss: 0.2993\n",
      "Epoch 958/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0431 - val_loss: 0.3294\n",
      "Epoch 959/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0479 - val_loss: 0.3213\n",
      "Epoch 960/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0434 - val_loss: 0.3137\n",
      "Epoch 961/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0393 - val_loss: 0.3249\n",
      "Epoch 962/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0364 - val_loss: 0.3050\n",
      "Epoch 963/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0421 - val_loss: 0.3205\n",
      "Epoch 964/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0420 - val_loss: 0.3239\n",
      "Epoch 965/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0419 - val_loss: 0.3133\n",
      "Epoch 966/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0416 - val_loss: 0.3072\n",
      "Epoch 967/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0375 - val_loss: 0.3126\n",
      "Epoch 968/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0408 - val_loss: 0.3303\n",
      "Epoch 969/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0438 - val_loss: 0.3105\n",
      "Epoch 970/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0335 - val_loss: 0.3159\n",
      "Epoch 971/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0369 - val_loss: 0.3148\n",
      "Epoch 972/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0423 - val_loss: 0.3057\n",
      "Epoch 973/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0433 - val_loss: 0.3169\n",
      "Epoch 974/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0397 - val_loss: 0.3136\n",
      "Epoch 975/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0395 - val_loss: 0.3302\n",
      "Epoch 976/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0426 - val_loss: 0.3093\n",
      "Epoch 977/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0380 - val_loss: 0.3056\n",
      "Epoch 978/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0411 - val_loss: 0.3224\n",
      "Epoch 979/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0405 - val_loss: 0.3163\n",
      "Epoch 980/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0382 - val_loss: 0.3128\n",
      "Epoch 981/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0341 - val_loss: 0.3257\n",
      "Epoch 982/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0493 - val_loss: 0.3180\n",
      "Epoch 983/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0395 - val_loss: 0.3124\n",
      "Epoch 984/1000\n",
      "57/57 [==============================] - 2s 36ms/step - loss: 0.0418 - val_loss: 0.3225\n",
      "Epoch 985/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0431 - val_loss: 0.3140\n",
      "Epoch 986/1000\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 0.0393 - val_loss: 0.3221\n",
      "Epoch 987/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0365 - val_loss: 0.3101\n",
      "Epoch 988/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0391 - val_loss: 0.3194\n",
      "Epoch 989/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0403 - val_loss: 0.3289\n",
      "Epoch 990/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0414 - val_loss: 0.3087\n",
      "Epoch 991/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0416 - val_loss: 0.3166\n",
      "Epoch 992/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0352 - val_loss: 0.3270\n",
      "Epoch 993/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0389 - val_loss: 0.3162\n",
      "Epoch 994/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0312 - val_loss: 0.3439\n",
      "Epoch 995/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0393 - val_loss: 0.3135\n",
      "Epoch 996/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0432 - val_loss: 0.3215\n",
      "Epoch 997/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0400 - val_loss: 0.3032\n",
      "Epoch 998/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0403 - val_loss: 0.3247\n",
      "Epoch 999/1000\n",
      "57/57 [==============================] - 2s 33ms/step - loss: 0.0398 - val_loss: 0.3189\n",
      "Epoch 1000/1000\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0346 - val_loss: 0.3142\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "LGE_model.compile(optimizer=adam,loss='mae')\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 20, restore_best_weights = True)\n",
    "# callbacks=[early_stopping]\n",
    "history = LGE_model.fit(train[:,0:29],train[:,29:30,2],epochs = 1000,batch_size = 20, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = LGE_model.predict(train[:,0:29])\n",
    "\n",
    "plt.plot(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train[:,29:30,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev = train[:,29:30,2]*Y\n",
    "plt.plot(ev)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1029"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(ev > 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
